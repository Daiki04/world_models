digraph {
	graph [size="21.9,21.9"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2367516731056 [label="
 (80, 3, 64, 64)" fillcolor=darkolivegreen1]
	2367293528848 [label=SigmoidBackward0]
	2367293523232 -> 2367293528848
	2367293523232 [label=ConvolutionBackward0]
	2367293522944 -> 2367293523232
	2367293522944 [label=ReluBackward0]
	2367663362336 -> 2367293522944
	2367663362336 [label=ConvolutionBackward0]
	2367663362096 -> 2367663362336
	2367663362096 [label=ReluBackward0]
	2367663361904 -> 2367663362096
	2367663361904 [label=ConvolutionBackward0]
	2367663370304 -> 2367663361904
	2367663370304 [label=ReluBackward0]
	2367663368432 -> 2367663370304
	2367663368432 [label=ConvolutionBackward0]
	2367663370160 -> 2367663368432
	2367663370160 [label=ViewBackward0]
	2367663370832 -> 2367663370160
	2367663370832 [label=AddmmBackward0]
	2367663370256 -> 2367663370832
	2367515015376 [label="decoder.l1.bias
 (1024)" fillcolor=lightblue]
	2367515015376 -> 2367663370256
	2367663370256 [label=AccumulateGrad]
	2367663371168 -> 2367663370832
	2367663371168 [label=AddBackward0]
	2367663367904 -> 2367663371168
	2367663367904 [label=AddmmBackward0]
	2367663370976 -> 2367663367904
	2367515014976 [label="encoder.mu.bias
 (32)" fillcolor=lightblue]
	2367515014976 -> 2367663370976
	2367663370976 [label=AccumulateGrad]
	2367663371456 -> 2367663367904
	2367663371456 [label=ViewBackward0]
	2367663370544 -> 2367663371456
	2367663370544 [label=ReluBackward0]
	2367663598192 -> 2367663370544
	2367663598192 [label=ConvolutionBackward0]
	2367663598288 -> 2367663598192
	2367663598288 [label=ReluBackward0]
	2367663598480 -> 2367663598288
	2367663598480 [label=ConvolutionBackward0]
	2367663598576 -> 2367663598480
	2367663598576 [label=ReluBackward0]
	2367663598768 -> 2367663598576
	2367663598768 [label=ConvolutionBackward0]
	2367663598864 -> 2367663598768
	2367663598864 [label=ReluBackward0]
	2367663599056 -> 2367663598864
	2367663599056 [label=ConvolutionBackward0]
	2367663599152 -> 2367663599056
	2367515014176 [label="encoder.conv1.weight
 (32, 3, 4, 4)" fillcolor=lightblue]
	2367515014176 -> 2367663599152
	2367663599152 [label=AccumulateGrad]
	2367663599104 -> 2367663599056
	2367515014096 [label="encoder.conv1.bias
 (32)" fillcolor=lightblue]
	2367515014096 -> 2367663599104
	2367663599104 [label=AccumulateGrad]
	2367663598816 -> 2367663598768
	2367515014336 [label="encoder.conv2.weight
 (64, 32, 4, 4)" fillcolor=lightblue]
	2367515014336 -> 2367663598816
	2367663598816 [label=AccumulateGrad]
	2367663598672 -> 2367663598768
	2367515014576 [label="encoder.conv2.bias
 (64)" fillcolor=lightblue]
	2367515014576 -> 2367663598672
	2367663598672 [label=AccumulateGrad]
	2367663598528 -> 2367663598480
	2367515014496 [label="encoder.conv3.weight
 (128, 64, 4, 4)" fillcolor=lightblue]
	2367515014496 -> 2367663598528
	2367663598528 [label=AccumulateGrad]
	2367663598384 -> 2367663598480
	2367515014656 [label="encoder.conv3.bias
 (128)" fillcolor=lightblue]
	2367515014656 -> 2367663598384
	2367663598384 [label=AccumulateGrad]
	2367663598240 -> 2367663598192
	2367515014896 [label="encoder.conv4.weight
 (256, 128, 4, 4)" fillcolor=lightblue]
	2367515014896 -> 2367663598240
	2367663598240 [label=AccumulateGrad]
	2367663598000 -> 2367663598192
	2367515014816 [label="encoder.conv4.bias
 (256)" fillcolor=lightblue]
	2367515014816 -> 2367663598000
	2367663598000 [label=AccumulateGrad]
	2367663370064 -> 2367663367904
	2367663370064 [label=TBackward0]
	2367663369200 -> 2367663370064
	2367515014736 [label="encoder.mu.weight
 (32, 1024)" fillcolor=lightblue]
	2367515014736 -> 2367663369200
	2367663369200 [label=AccumulateGrad]
	2367663369920 -> 2367663371168
	2367663369920 [label=MulBackward0]
	2367663371840 -> 2367663369920
	2367663371840 [label=SqrtBackward0]
	2367663597568 -> 2367663371840
	2367663597568 [label=ExpBackward0]
	2367663598912 -> 2367663597568
	2367663598912 [label=AddmmBackward0]
	2367663598960 -> 2367663598912
	2367515015056 [label="encoder.logvar.bias
 (32)" fillcolor=lightblue]
	2367515015056 -> 2367663598960
	2367663598960 [label=AccumulateGrad]
	2367663371456 -> 2367663598912
	2367663599008 -> 2367663598912
	2367663599008 [label=TBackward0]
	2367663599200 -> 2367663599008
	2367515015216 [label="encoder.logvar.weight
 (32, 1024)" fillcolor=lightblue]
	2367515015216 -> 2367663599200
	2367663599200 [label=AccumulateGrad]
	2367663366464 -> 2367663370832
	2367663366464 [label=TBackward0]
	2367663370640 -> 2367663366464
	2367515015136 [label="decoder.l1.weight
 (1024, 32)" fillcolor=lightblue]
	2367515015136 -> 2367663370640
	2367663370640 [label=AccumulateGrad]
	2367663370352 -> 2367663368432
	2367515015456 [label="decoder.deconv1.weight
 (1024, 128, 5, 5)" fillcolor=lightblue]
	2367515015456 -> 2367663370352
	2367663370352 [label=AccumulateGrad]
	2367663368192 -> 2367663368432
	2367515015536 [label="decoder.deconv1.bias
 (128)" fillcolor=lightblue]
	2367515015536 -> 2367663368192
	2367663368192 [label=AccumulateGrad]
	2367663368576 -> 2367663361904
	2367515015776 [label="decoder.deconv2.weight
 (128, 64, 5, 5)" fillcolor=lightblue]
	2367515015776 -> 2367663368576
	2367663368576 [label=AccumulateGrad]
	2367663361808 -> 2367663361904
	2367515015696 [label="decoder.deconv2.bias
 (64)" fillcolor=lightblue]
	2367515015696 -> 2367663361808
	2367663361808 [label=AccumulateGrad]
	2367663362288 -> 2367663362336
	2367515015936 [label="decoder.deconv3.weight
 (64, 32, 6, 6)" fillcolor=lightblue]
	2367515015936 -> 2367663362288
	2367663362288 [label=AccumulateGrad]
	2367663362048 -> 2367663362336
	2367515016016 [label="decoder.deconv3.bias
 (32)" fillcolor=lightblue]
	2367515016016 -> 2367663362048
	2367663362048 [label=AccumulateGrad]
	2367293523712 -> 2367293523232
	2367515016096 [label="decoder.deconv4.weight
 (32, 3, 6, 6)" fillcolor=lightblue]
	2367515016096 -> 2367293523712
	2367293523712 [label=AccumulateGrad]
	2367293526832 -> 2367293523232
	2367515016336 [label="decoder.deconv4.bias
 (3)" fillcolor=lightblue]
	2367515016336 -> 2367293526832
	2367293526832 [label=AccumulateGrad]
	2367293528848 -> 2367516731056
}
