{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchviz import make_dot\n",
    "from torchinfo import summary\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import gym\n",
    "import datetime\n",
    "import time\n",
    "import os\n",
    "import tqdm\n",
    "# import cma\n",
    "from PIL import Image\n",
    "import torch.multiprocessing as mp\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"Encoder\"\"\"\n",
    "\n",
    "    def __init__(self, z_dim=32):\n",
    "        super().__init__()\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, 4, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 4, stride=2)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 4, stride=2) \n",
    "        self.conv4 = nn.Conv2d(128, 256, 4, stride=2)\n",
    "\n",
    "        self.mu = nn.Linear(256*2*2, z_dim)\n",
    "        self.logvar = nn.Linear(256*2*2, z_dim)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [batch_size, 3, 64, 64]\n",
    "        c1 = self.conv1(x) # (64x64x3) -> (31x31x32)\n",
    "        h1 = self.relu(c1) # (31x31x32) -> (31x31x32)\n",
    "        c2 = self.conv2(h1) # (31x31x32) -> (14x14x64)\n",
    "        h2 = self.relu(c2) # (14x14x64) -> (14x14x64)\n",
    "        c3 = self.conv3(h2) # (14x14x64) -> (6x6x128)\n",
    "        h3 = self.relu(c3) # (6x6x128) -> (6x6x128)\n",
    "        c4 = self.conv4(h3) # (6x6x128) -> (2x2x256)\n",
    "        h4 = self.relu(c4) # (2x2x256) -> (2x2x256)\n",
    "\n",
    "        d1 = h4.view(-1, 256*2*2) # (2x2x256) -> (1024)\n",
    "\n",
    "        mu = self.mu(d1) # (1024) -> (32)\n",
    "        logvar = self.logvar(d1) # (1024) -> (32)\n",
    "        var = torch.exp(logvar)\n",
    "        std = torch.sqrt(var)\n",
    "\n",
    "        ep = torch.randn_like(std)\n",
    "\n",
    "        z = mu + ep * std # (32) -> (32)\n",
    "\n",
    "        return z, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"\"\"Decoder\"\"\"\n",
    "    def __init__(self, z_dim=32):\n",
    "        super().__init__()\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "        self.l1 = nn.Linear(z_dim, 1024*1*1)\n",
    "\n",
    "        self.deconv1 = nn.ConvTranspose2d(1024, 128, 5, stride=2)\n",
    "        self.deconv2 = nn.ConvTranspose2d(128, 64, 5, stride=2)\n",
    "        self.deconv3 = nn.ConvTranspose2d(64, 32, 6, stride=2)\n",
    "        self.deconv4 = nn.ConvTranspose2d(32, 3, 6, stride=2)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, z):\n",
    "        # z: [batch_size, 32]\n",
    "        d1 = self.l1(z) # (32) -> (1024)\n",
    "        d1 = d1.view(-1, 1024, 1, 1) # (1024) -> (1x1x1024)\n",
    "\n",
    "        dc1 = self.deconv1(d1) # (1x1x1024) -> (5x5x128)\n",
    "        h1 = self.relu(dc1) # (5x5x128) -> (5x5x128)\n",
    "        dc2 = self.deconv2(h1) # (5x5x128) -> (13x13x64)\n",
    "        h2 = self.relu(dc2) # (13x13x64) -> (13x13x64)\n",
    "        dc3 = self.deconv3(h2) # (13x13x64) -> (30x30x32)\n",
    "        h3 = self.relu(dc3) # (30x30x32) -> (30x30x32)\n",
    "        dc4 = self.deconv4(h3) # (30x30x32) -> (64x64x3)\n",
    "        x = self.sigmoid(dc4) # (64x64x3) -> (64x64x3)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    '''VAE'''\n",
    "    def __init__(self, z_dim=32):\n",
    "        super().__init__()\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "        self.encoder = Encoder(z_dim)\n",
    "        self.decoder = Decoder(z_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z, mu, logvar = self.encoder(x)\n",
    "        x = self.decoder(z)\n",
    "\n",
    "        return x, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(encoder, (3, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(decoder, (32,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "vae = VAE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(vae, (3, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_data = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CIFAR10(root='./data3', train=True, download=True, transform=transform_data)\n",
    "test_dataset = CIFAR10(root='./data3', train=False, download=True, transform=transform_data)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(predict, target, ave, log_dev):\n",
    "  bce_loss = F.binary_cross_entropy(predict, target, reduction='sum')\n",
    "  kl_loss = -0.5 * torch.sum(1 + log_dev - ave**2 - log_dev.exp())\n",
    "  loss = bce_loss + kl_loss\n",
    "  return loss\n",
    "\n",
    "net = VAE().to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    "history = {'train_loss': []}\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, (img, _) in enumerate(train_loader):\n",
    "        img = img.to(device)\n",
    "        output, mu, logvar = net(img)\n",
    "        loss = criterion(output, img, mu, logvar)\n",
    "        history['train_loss'].append(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = make_dot(output, params=dict(net.named_parameters()))\n",
    "g.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MDN-RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MDMRNN(nn.Module):\n",
    "#     \"\"\"MDN-RNN\"\"\"\n",
    "#     def __init__(self, num_mixtures, hidden_size,  z_size, a_size, r_size, num_layers, batch_size, sequence_len, output_size):\n",
    "#         super().__init__()\n",
    "#         self.z_size = z_size # 潜在状態の次元\n",
    "#         self.a_size = a_size # 行動の次元\n",
    "#         self.r_size = r_size # 報酬の次元\n",
    "#         self.input_size = z_size + a_size + r_size # 入力の次元\n",
    "#         self.num_mixtures = num_mixtures # 正規分布の数\n",
    "#         self.hidden_size = hidden_size # 隠れ層の次元\n",
    "#         self.num_layers = num_layers # LSTMの層数\n",
    "#         self.batch_size = batch_size # バッチサイズ\n",
    "#         self.lstm = nn.LSTM(self.input_size, self.hidden_size, self.num_layers) # LSTM\n",
    "#         self.sequence_len = sequence_len # シーケンスの長さ\n",
    "#         self.output_size = output_size # 出力の次元\n",
    "#         self.dense = nn.Linear(self.hidden_size, self.output_size * num_mixtures * 3) # 全結合層\n",
    "    \n",
    "#     def forward(self, x, hidden_state, cell_state):\n",
    "#         x = x.view(self.sequence_len, self.batch_size, self.input_size)\n",
    "#         z, hidden_states = self.lstm(x, (hidden_state, cell_state))\n",
    "#         hidden = hidden_states[0]\n",
    "#         cell = hidden_states[1]\n",
    "#         z = z.view(-1, self.hidden_size)\n",
    "#         z = self.dense(z)\n",
    "#         z = z.view(-1, self.num_mixtures * 3)\n",
    "#         out_logmix, out_mean, out_log_std = get_mdn_coef(z, self.num_mixtures)\n",
    "#         return out_logmix, out_mean, out_log_std, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    \"\"\"LSTM\"\"\"\n",
    "    def __init__(self, z_size, a_size, hidden_size=256, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.z_size = z_size\n",
    "        self.a_size = a_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = z_size + a_size\n",
    "        self.lstm = nn.LSTM(self.input_size, self.hidden_size, num_layers, batch_first=False) # LSTM：入力サイズ、隠れ層サイズ、層数、バイアス、バッチファースト\n",
    "\n",
    "    def forward(self, x, hidden_state, cell_state):\n",
    "        # x: [seq_len, batch_size, z_size + a_size]\n",
    "        output, hidden_cell = self.lstm(x, (hidden_state, cell_state))\n",
    "        hidden = hidden_cell[0]\n",
    "        cell = hidden_cell[1]\n",
    "        # output: [seq_len, batch_size, hidden_size]\n",
    "        # hidden: [num_layers, batch_size, hidden_size]\n",
    "        # cell: [num_layers, batch_size, hidden_size]\n",
    "        return output, hidden, cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    \"\"\"LSTM\"\"\"\n",
    "    def __init__(self, z_size, a_size, hidden_size=256, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.z_size = z_size\n",
    "        self.a_size = a_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = z_size + a_size\n",
    "        self.lstm = nn.LSTM(self.input_size, self.hidden_size, num_layers, batch_first=False) # LSTM：入力サイズ、隠れ層サイズ、層数、バイアス、バッチファースト\n",
    "    \n",
    "    def forward(self, x, hidden_state, cell_state):\n",
    "        output, hidden_cell = self.lstm(x, (hidden_state, cell_state))\n",
    "        hidden = hidden_cell[0]\n",
    "        cell = hidden_cell[1]\n",
    "        return output, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MDN(nn.Module):\n",
    "    \"\"\"Mixture Density Network\"\"\"\n",
    "    def __init__(self, hidden_size=256, z_size=32, r_size=0, num_gaussians=5):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.z_size = z_size\n",
    "        self.num_gaussians = num_gaussians\n",
    "        self.output_size = num_gaussians * 3 *  z_size + r_size # 3: mu, log_sigma, pi, r_size: reward\n",
    "\n",
    "        self.fc = nn.Linear(self.hidden_size, self.output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: [seq_len, batch_size, hidden_size]\n",
    "        output = self.fc(x)\n",
    "        # output: [seq_len, batch_size, num_gaussians * 3 * z_size + r_size]\n",
    "        p, mu, logsigma, r = self.split_mdn_params(output)\n",
    "        return p, mu, logsigma, r\n",
    "    \n",
    "    def split_mdn_params(self, output):\n",
    "        # output: [seq_len, batch_size, num_gaussians * 3 * z_size + r_size]\n",
    "        p = output[:, :, :self.num_gaussians]\n",
    "        mu = output[:, :, self.num_gaussians:self.num_gaussians * (self.z_size + 1)]\n",
    "        logsigma = output[:, :, self.num_gaussians * (self.z_size + 1):self.num_gaussians * (self.z_size * 2 + 1)]\n",
    "        r = output[:, :, -1]\n",
    "\n",
    "        # p: [seq_len, batch_size, num_gaussians]\n",
    "        # mu: [seq_len, batch_size, num_gaussians * z_size]\n",
    "        # sigma: [seq_len, batch_size, num_gaussians * z_size]\n",
    "        # r: [seq_len, batch_size, r_size]\n",
    "\n",
    "        p = F.softmax(p, dim=2)\n",
    "        sigma = torch.exp(sigma)\n",
    "        return p, mu, sigma, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MDRNN(nn.Module):\n",
    "    \"\"\"MDN-RNN\"\"\"\n",
    "    def __init__(self, z_size, a_size, r_size, hidden_size=256, num_layers=1, num_gaussians=5):\n",
    "        super().__init__()\n",
    "        self.z_size = z_size\n",
    "        self.a_size = a_size\n",
    "        self.r_size = r_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.num_gaussians = num_gaussians\n",
    "\n",
    "        self.lstm = LayerNormBasicLSTM(z_size, a_size, hidden_size, num_layers)\n",
    "        self.mdn = MDN(hidden_size, z_size, r_size, num_gaussians)\n",
    "\n",
    "    def forward(self, z, a):\n",
    "        # z: [seq_len, batch_size, z_size]\n",
    "        # a: [seq_len, batch_size, a_size]\n",
    "        za = torch.cat([z, a], dim=2)\n",
    "        # za: [seq_len, batch_size, z_size + a_size]\n",
    "        output, (h_n, c_n) = self.lstm(za)\n",
    "        # output: [seq_len, batch_size, hidden_size]\n",
    "        # h_n: [num_layers, batch_size, hidden_size]\n",
    "        # c_n: [num_layers, batch_size, hidden_size]\n",
    "        p, mu, sigma, r = self.mdn(output)\n",
    "        # p: [seq_len, batch_size, num_gaussians]\n",
    "        # mu: [seq_len, batch_size, num_gaussians * z_size]\n",
    "        # sigma: [seq_len, batch_size, num_gaussians * z_size]\n",
    "        # r: [seq_len, batch_size, r_size]\n",
    "        return output, p, mu, sigma, r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = LayerNormBasicLSTM(32, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(lstm, (1, 1, 35))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdn = MDN(256, 32, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(mdn, (1, 1, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdnrnn = MDRNN(32, 3, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(mdnrnn, [(1, 1, 32), (1, 1, 3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Controller(nn.Module):\n",
    "    \"\"\"Controller\"\"\"\n",
    "\n",
    "    def __init__(self, a_size, h_size=256, z_size=32):\n",
    "        super().__init__()\n",
    "        self.a_size = a_size\n",
    "        self.h_size = h_size\n",
    "        self.z_size = z_size\n",
    "        self.input_size = z_size + h_size\n",
    "        self.fc = nn.Linear(self.input_size, a_size)\n",
    "\n",
    "    def forward(self, z, h):\n",
    "        # z: [batch_size, z_size]\n",
    "        # h: [batch_size, h_size]\n",
    "        zh = torch.cat([z, h], dim=1)\n",
    "        # zh: [batch_size, z_size + h_size]\n",
    "        a = self.fc(zh)\n",
    "        # a: [batch_size, a_size]\n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Controller(3)\n",
    "\n",
    "summary(c, [(1, 32), (1, 256)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym.spaces.box import Box\n",
    "from gym.envs.box2d.car_racing import CarRacing\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.random as nr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CarRacing-v2')\n",
    "state, _ = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCREEN_X = 64 # 画像の横幅\n",
    "SCREEN_Y = 64 # 画像の縦幅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ゲームの選択\n",
    "env = gym.make('CarRacing-v2', render_mode='rgb_array')\n",
    "\n",
    "#デフォルトのactionsの確認（steer, gas, brakeの3次元連続値）\n",
    "print('env.action_space: {}'.format(env.action_space))\n",
    "\n",
    "#アクションを離散値で用意しておく\n",
    "actions = np.array([[ 0, 0, 0],  #actions[0]：何もしない（＝等速直線運動）\n",
    "                    [ 0, 1, 0],  #actions[1]：加速\n",
    "                    [ 0, 0, 1],  #actions[2]：減速\n",
    "                    [ 1, 0, 0],  #actions[3]：右旋回\n",
    "                    [-1, 0, 0]]) #actions[4]：左旋回\n",
    "print('actions:\\n{}'.format(actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import os\n",
    "\n",
    "env = gym.make('CarRacing-v2', render_mode='rgb_array')\n",
    "\n",
    "def get_rollouts(num_rollouts=10000, reflesh_rate=20, file_dir='./data/'):\n",
    "    for i in tqdm.tqdm(range(num_rollouts)):\n",
    "        state_sequence = []\n",
    "        action_sequence = []\n",
    "        reward_sequence = []\n",
    "        done_sequence = []\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        iter = 0\n",
    "        while not done:\n",
    "            if iter % reflesh_rate == 0:\n",
    "                if iter < 20:\n",
    "                    steering = -0.1\n",
    "                    acceleration = 1\n",
    "                    brake = 0\n",
    "                else:\n",
    "                    steering = nr.uniform(-1, 1)\n",
    "                    acceleration = nr.uniform(0, 1)\n",
    "                    brake = nr.uniform(0, 1)\n",
    "            action = np.array([steering, acceleration, brake])\n",
    "            state, reward, done, _, _ = env.step(action)\n",
    "            state = reshape_state(state)\n",
    "            state_sequence.append(state)\n",
    "            action_sequence.append(action)\n",
    "            reward_sequence.append(reward)\n",
    "            done_sequence.append(done)\n",
    "            iter += 1\n",
    "        np.savez_compressed(os.path.join(file_dir, 'rollout_{}.npz'.format(i)), state=state_sequence, action=action_sequence, reward=reward_sequence, done=done_sequence)\n",
    "\n",
    "def load_rollout(idx_rolloout, file_dir='./data/'):\n",
    "    data = np.load(os.path.join(file_dir, 'rollout_{}.npz'.format(idx_rolloout)))\n",
    "    return data['state'], data['action'], data['reward'], data['done']\n",
    "\n",
    "def reshape_state(state):\n",
    "    HEIGHT = 64\n",
    "    WIDTH = 64\n",
    "    state = state[0:84, :, :]\n",
    "    state = np.array(Image.fromarray(state).resize((HEIGHT, WIDTH)))\n",
    "    state = state / 255.0\n",
    "    return state\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshape_state(state[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(state[0])\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(reshape_state(state[0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state, _ = env.reset()\n",
    "\n",
    "#初期画像を表示\n",
    "plt.figure()\n",
    "plt.imshow(env.render())\n",
    "plt.show()\n",
    "\n",
    "#ランダムにアクション（1アクションは4フレーム継続）\n",
    "for i in range(10):\n",
    "    for _ in range(4):\n",
    "        #アクションの選択\n",
    "        rand = nr.randint(5)\n",
    "\n",
    "        #状態の更新\n",
    "        state, reward, done, info, _ = env.step(actions[rand])\n",
    "        print('reward:{}'.format(reward))\n",
    "        \n",
    "    #1アクション（＝4フレーム）毎に画像を表示\n",
    "    plt.figure()\n",
    "    plt.imshow(env.render())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "\n",
    "observation, reward, done, info, _ = env.step(env.action_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import os\n",
    "import gym\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "import argparse\n",
    "\n",
    "class CarRacing_rollouts():\n",
    "    def __init__(self, max_episode=200):\n",
    "        self.env = gym.make('CarRacing-v2', render_mode='rgb_array', domain_randomize=True)\n",
    "        self.env.reset()\n",
    "        self.file_dir = './data/'\n",
    "        self.max_episode = 200\n",
    "\n",
    "    def get_rollout(self, file_number, reflesh_rate=20):\n",
    "        state_sequence = []\n",
    "        action_sequence = []\n",
    "        reward_sequence = []\n",
    "        done_sequence = []\n",
    "        state = self.env.reset(seed=file_number)\n",
    "        done = False\n",
    "        iter = 0\n",
    "        while (not done) and (iter < self.max_episode):\n",
    "            if iter % reflesh_rate == 0:\n",
    "                if iter < 20:\n",
    "                    steering = -0.1\n",
    "                    acceleration = 1\n",
    "                    brake = 0\n",
    "                else:\n",
    "                    steering = nr.uniform(-1, 1)\n",
    "                    acceleration = nr.uniform(0, 1)\n",
    "                    brake = nr.uniform(0, 1)\n",
    "            action = np.array([steering, acceleration, brake])\n",
    "            state, reward, done, _, _ = self.env.step(action)\n",
    "            state = self.reshape_state(state)\n",
    "            state_sequence.append(state)\n",
    "            action_sequence.append(action)\n",
    "            reward_sequence.append(reward)\n",
    "            done_sequence.append(done)\n",
    "            iter += 1\n",
    "        np.savez_compressed(os.path.join(self.file_dir, 'rollout_{}.npz'.format(i)), state=state_sequence, action=action_sequence, reward=reward_sequence, done=done_sequence)\n",
    "        print('rollout_{}.npz is saved.'.format(i))\n",
    "\n",
    "    def get_rollouts(self, num_rollouts=10000, reflesh_rate=20):\n",
    "        start_idx = 0\n",
    "        if os.path.exists(self.file_dir):\n",
    "            start_idx = len(os.listdir(self.file_dir)) \n",
    "        for i in tqdm.tqdm(range(start_idx, num_rollouts+1)):\n",
    "            state_sequence = []\n",
    "            action_sequence = []\n",
    "            reward_sequence = []\n",
    "            done_sequence = []\n",
    "            state = self.env.reset()\n",
    "            done = False\n",
    "            iter = 0\n",
    "            while not done:\n",
    "                if iter % reflesh_rate == 0:\n",
    "                    if iter < 20:\n",
    "                        steering = -0.1\n",
    "                        acceleration = 1\n",
    "                        brake = 0\n",
    "                    else:\n",
    "                        steering = nr.uniform(-1, 1)\n",
    "                        acceleration = nr.uniform(0, 1)\n",
    "                        brake = nr.uniform(0, 1)\n",
    "                action = np.array([steering, acceleration, brake])\n",
    "                state, reward, done, _, _ = self.env.step(action)\n",
    "                state = self.reshape_state(state)\n",
    "                state_sequence.append(state)\n",
    "                action_sequence.append(action)\n",
    "                reward_sequence.append(reward)\n",
    "                done_sequence.append(done)\n",
    "                iter += 1\n",
    "            np.savez_compressed(os.path.join(self.file_dir, 'rollout_{}.npz'.format(i)), state=state_sequence, action=action_sequence, reward=reward_sequence, done=done_sequence)\n",
    "\n",
    "    def load_rollout(self, idx_rolloout):\n",
    "        data = np.load(os.path.join(self.file_dir, 'rollout_{}.npz'.format(idx_rolloout)))\n",
    "        return data['state'], data['action'], data['reward'], data['done']\n",
    "\n",
    "    def reshape_state(self, state):\n",
    "        HEIGHT = 64\n",
    "        WIDTH = 64\n",
    "        state = state[0:84, :, :]\n",
    "        state = np.array(Image.fromarray(state).resize((HEIGHT, WIDTH)))\n",
    "        state = state / 255.0\n",
    "        return state\n",
    "    \n",
    "    def make_gif(self, idx_rolloout):\n",
    "        state, _, _, _ = self.load_rollout(idx_rolloout, self.file_dir)\n",
    "        state = state * 255.0\n",
    "        state = state.astype(np.uint8)\n",
    "        for i in range(len(state)):\n",
    "            img = Image.fromarray(state[i])\n",
    "            img.save(os.path.join(self.file_dir, 'rollout_{}.gif'.format(idx_rolloout, i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import time\n",
    "\n",
    "# 並列処理の実行：CarRacingのロールアウトデータの取得\n",
    "Cr = CarRacing_rollouts()\n",
    "with ProcessPoolExecutor(max_workers=os.cpu_count()) as executor:\n",
    "    executor.submit(, num_rollouts=10000, reflesh_rate=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "env = gym.make('CarRacing-v2', render_mode='rgb_array')\n",
    "s, _ = env.reset(seed=123)\n",
    "s, _ = env.reset()\n",
    "\n",
    "#初期画像を表示\n",
    "pil_im = Image.fromarray(s[0:84, :, :])\n",
    "pil_im.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_state(s):\n",
    "    HEIGHT = 64\n",
    "    WIDTH = 64\n",
    "    s = state[0:84, :, :]\n",
    "    s = np.array(Image.fromarray(s).resize((HEIGHT, WIDTH)))\n",
    "    s = s / 255.0\n",
    "    return s\n",
    "\n",
    "re_state = reshape_state(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_npz = np.savez_compressed('./re_sate.npz', state=re_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_state = np.load('./re_sate.npz')['state'] * 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pil_im_re = Image.fromarray(re_state.astype(\"uint8\"))\n",
    "pil_im_re.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_sequence = []\n",
    "action_sequence = []\n",
    "reward_sequence = []\n",
    "done_sequence = []\n",
    "state = env.reset()\n",
    "done = False\n",
    "iter = 0\n",
    "max_episode = 300\n",
    "reflesh_rate = 20\n",
    "while (not done) and iter < max_episode:\n",
    "    if iter % reflesh_rate == 0:\n",
    "        if iter < 20:\n",
    "            steering = -0.1\n",
    "            acceleration = 1\n",
    "            brake = 0\n",
    "        else:\n",
    "            steering = nr.uniform(-1, 1)\n",
    "            acceleration = nr.uniform(0, 1)\n",
    "            brake = nr.uniform(0, 1)\n",
    "    action = np.array([steering, acceleration, brake])\n",
    "    state, reward, done, _, _ = env.step(action)\n",
    "    state = reshape_state(state)\n",
    "    state_sequence.append(state)\n",
    "    action_sequence.append(action)\n",
    "    reward_sequence.append(reward)\n",
    "    done_sequence.append(done)\n",
    "    iter += 1\n",
    "np.savez_compressed('rollout_test.npz', state=state_sequence, action=action_sequence, reward=reward_sequence, done=done_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_states = np.load('rollout_test.npz')['state']\n",
    "re_test_states = test_states[0] * 255.0\n",
    "re_test_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_re_test_states = Image.fromarray(re_test_states.astype(\"uint8\"))\n",
    "im_re_test_states.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.VAE import VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rollout\n",
    "\n",
    "rollout = rollout.CarRacing_rollouts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "lr = 0.001\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "vae = VAE().to(device)\n",
    "optimizer = torch.optim.Adam(vae.parameters(), lr=lr)\n",
    "\n",
    "# 学習\n",
    "num_batches = 1\n",
    "num_epochs = 10000\n",
    "\n",
    "def loss_function(label, predict, mu, log_var, kl_tolerance=0.5, z_size=32):\n",
    "    r_loss = torch.sum((predict - label).pow(2), dim=(1, 2, 3))\n",
    "    r_loss = torch.mean(r_loss)\n",
    "    kl_loss = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp(), dim=1)\n",
    "    kl_loss = torch.max(kl_loss, kl_loss.new([kl_tolerance * z_size]))\n",
    "    kl_loss = torch.mean(kl_loss)\n",
    "    return r_loss.detach().cpu().numpy(), kl_loss.detach().cpu().numpy(), r_loss + kl_loss\n",
    "\n",
    "for batch in range(num_batches):\n",
    "    for epoch in range(num_epochs):\n",
    "        states, _, _, _ = rollout.load_rollout(epoch)\n",
    "        inputs = torch.tensor(states).permute(0, 3, 1, 2).float()\n",
    "        labels = torch.tensor(states).permute(0, 3, 1, 2).float()\n",
    "        inputs_train = inputs[0:int(len(inputs)*0.7)]\n",
    "        inputs_test = inputs[int(len(inputs)*0.7):]\n",
    "        labels_train = labels[0:int(len(inputs)*0.7)]\n",
    "        labels_test = labels[int(len(inputs)*0.7):]\n",
    "\n",
    "        #GPU\n",
    "        inputs_train = inputs_train.to(device)\n",
    "        inputs_test = inputs_test.to(device)\n",
    "        labels_train = labels_train.to(device)\n",
    "        labels_test = labels_test.to(device)\n",
    "\n",
    "        # 学習\n",
    "        vae.train()\n",
    "        optimizer.zero_grad()\n",
    "        predict, mu, log_var = vae(inputs_train)\n",
    "        r_loss, kl_loss, loss = loss_function(labels_train, predict, mu, log_var)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # テスト\n",
    "        vae.eval()\n",
    "        predict, mu, log_var = vae(inputs_test)\n",
    "        r_loss, kl_loss, loss = loss_function(labels_test, predict, mu, log_var)\n",
    "\n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Loss: {:.4f}, r_loss: {:.4f}, kl_loss: {:.4f}'.format(epoch + 1, num_epochs, loss.item(), r_loss, kl_loss))\n",
    "\n",
    "        if (epoch + 1) % 1000 == 0:\n",
    "            train_hist = {}\n",
    "            train_hist['loss'] = []\n",
    "            train_hist['loss'].append(loss.item())\n",
    "            train_hist['r_loss'] = []\n",
    "            train_hist['r_loss'].append(r_loss.item())\n",
    "            train_hist['kl_loss'] = []\n",
    "            train_hist['kl_loss'].append(kl_loss.item())\n",
    "\n",
    "            test_hist = {}\n",
    "            test_hist['loss'] = []\n",
    "            test_hist['loss'].append(loss.item())\n",
    "            test_hist['r_loss'] = []\n",
    "            test_hist['r_loss'].append(r_loss.item())\n",
    "            test_hist['kl_loss'] = []\n",
    "            test_hist['kl_loss'].append(kl_loss.item())\n",
    "\n",
    "    # モデルの保存\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': vae.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "    }, './vae.pth')\n",
    "\n",
    "    # historyの保存\n",
    "    hist_dir = './hist'\n",
    "    hist_date = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    if not os.path.exists(hist_dir):\n",
    "        os.makedirs(hist_dir)\n",
    "    \n",
    "    if not os.path.exists(os.path.join(hist_dir, hist_date)):\n",
    "        os.makedirs(os.path.join(hist_dir, hist_date))\n",
    "    \n",
    "    df_hist = pd.DataFrame(train_hist)\n",
    "    df_hist.to_csv(os.path.join(hist_dir, hist_date, 'train_hist.csv'), index=False)\n",
    "    df_hist = pd.DataFrame(test_hist)\n",
    "    df_hist.to_csv(os.path.join(hist_dir, hist_date, 'test_hist.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rollout\n",
    "\n",
    "rollouts = rollout.CarRacing_rollouts()\n",
    "\n",
    "states, _, _, _ = rollouts.load_rollout(10)\n",
    "t100 = states[150]\n",
    "t100_255 = states[100] * 255.0\n",
    "pil_image = Image.fromarray(t100_255.astype(\"uint8\"))\n",
    "pil_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t100.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t100 = t100.reshape(1, 3, 64, 64)\n",
    "t100 = torch.tensor(t100).float()\n",
    "t100 = t100.to(device)\n",
    "t100.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t100_vae = vae(t100)\n",
    "t100_vae[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t100_vae_255 = t100_vae[0].detach().cpu().permute(0, 2, 3, 1).numpy() * 255.0\n",
    "t100_vae_255 = t100_vae_255[0]\n",
    "t100_vae_255.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pil_image_vae = Image.fromarray(t100_vae_255.astype(\"uint8\"))\n",
    "pil_image_vae.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist = pd.DataFrame([train_hist[\"loss\"][-1], train_hist[\"rmse_loss\"][-1], train_hist[\"kl_loss\"][-1]])\n",
    "df_hist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist = pd.DataFrame([train_hist[\"loss\"][-1], train_hist[\"rmse_loss\"][-1], train_hist[\"kl_loss\"][-1]])\n",
    "df_hist.to_csv(os.path.join(hist_dir, hist_date, 'train_hist.csv'), index=False)\n",
    "df_hist = pd.DataFrame(test_hist)\n",
    "df_hist.to_csv(os.path.join(hist_dir, hist_date, 'test_hist.csv'), index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MDN-RNN Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.MDN_RNN import MDNRNN\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "mdnrnn = MDNRNN(z_size=32, a_size=3, r_size=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(mdnrnn, [(1, 1, 32), (1, 1, 3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.VAE import VAE\n",
    "\n",
    "vae = VAE()\n",
    "vae.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rollout\n",
    "\n",
    "rollout = rollout.CarRacing_rollouts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states, _, _, _ = rollout.load_rollout(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z, mu, logvar = vae.encode(torch.tensor(states).permute(0, 3, 1, 2).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "lr = 0.001\n",
    "optimizer = torch.optim.Adam(mdnrnn.parameters(), lr=lr)\n",
    "\n",
    "# 学習\n",
    "num_batches = 20\n",
    "num_epochs = 100\n",
    "\n",
    "train_hist = {}\n",
    "train_hist['epoch'] = []\n",
    "train_hist['loss'] = []\n",
    "train_hist['rmse_loss'] = []\n",
    "train_hist['kl_loss'] = []\n",
    "\n",
    "test_hist = {}\n",
    "test_hist['epoch'] = []\n",
    "test_hist['loss'] = []\n",
    "test_hist['rmse_loss'] = []\n",
    "test_hist['kl_loss'] = []\n",
    "\n",
    "def loss_function(pi, sigma, mu, target):\n",
    "    # gaussian mixture loss\n",
    "    gausian_prob = (1 / (sigma * torch.sqrt(2 * np.pi))) * torch.exp(- (target - mu)**2 / (2 * sigma**2))\n",
    "    gausian_prob = torch.prod(gausian_prob, dim=2)\n",
    "    gausian_prob = torch.sum(gausian_prob * pi, dim=1)\n",
    "    gausian_prob = -torch.log(gausian_prob + 1e-5)\n",
    "    gausian_prob = torch.mean(gausian_prob)\n",
    "\n",
    "    return gausian_prob\n",
    "    \n",
    "\n",
    "for batch in range(num_batches):\n",
    "    for epoch in range(num_epochs):\n",
    "        states, actions, _, _ = rollout.load_rollout(epoch)\n",
    "        z = vae.encode(torch.tensor(states).permute(0, 3, 1, 2).float())[0].detach().numpy()\n",
    "\n",
    "        inputs_train_z = z[0:int(len(z)*0.7)-1]\n",
    "        inputs_test_z = z[int(len(z)*0.7)-1:int(len(z))-1]\n",
    "        inputs_train_a = actions[0:int(len(z)*0.7)-1]\n",
    "        inputs_test_a = actions[int(len(z)*0.7)-1:int(len(z))-1]\n",
    "\n",
    "        labels_train_z = z[1:int(len(z)*0.7)]\n",
    "        labels_test_z = z[int(len(z)*0.7):]\n",
    "\n",
    "        inputs_train_z = torch.tensor(inputs_train_z).float()\n",
    "        inputs_test_z = torch.tensor(inputs_test_z).float()\n",
    "        inputs_train_a = torch.tensor(inputs_train_a).float()\n",
    "        inputs_test_a = torch.tensor(inputs_test_a).float()\n",
    "        labels_train_z = torch.tensor(labels_train_z).float()\n",
    "        labels_test_z = torch.tensor(labels_test_z).float()\n",
    "\n",
    "        inputs_train_z = inputs_train_z.view(-1, 1, 32)\n",
    "        inputs_test_z = inputs_test_z.view(-1, 1, 32)\n",
    "        inputs_train_a = inputs_train_a.view(-1, 1, 3)\n",
    "        inputs_test_a = inputs_test_a.view(-1, 1, 3)\n",
    "        labels_train_z = labels_train_z.view(-1, 1, 32)\n",
    "        labels_test_z = labels_test_z.view(-1, 1, 32)\n",
    "\n",
    "        # 学習\n",
    "        mdnrnn.train()\n",
    "        optimizer.zero_grad()\n",
    "        h, pi, mu, sigma, r = mdnrnn(inputs_train_z, inputs_train_a)\n",
    "        loss = loss_function(pi, sigma, mu, labels_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_hist['loss'].append(loss.item())\n",
    "\n",
    "        # テスト\n",
    "        mdnrnn.eval()\n",
    "        h, pi, mu, sigma, r = mdnrnn(inputs_test)\n",
    "        loss = loss_function(pi, sigma, mu, labels_test)\n",
    "        test_hist['loss'].append(loss.item())\n",
    "\n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            print('epoch [{}/{}], loss: {:.4f}, rmse_loss: {:.4f}, kl_loss: {:.4f}'.format(epoch + 1, num_epochs, loss.item(), rmse_loss.item(), kl_loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train_z.view(-1, 1, 32).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat([inputs_train_z, inputs_train_a], dim=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.VAE import VAE\n",
    "\n",
    "vae = VAE()\n",
    "optimizer = torch.optim.Adam(vae.parameters(), lr=0.001)\n",
    "\n",
    "checkpoint = torch.load('vae.pth')\n",
    "vae.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rollout\n",
    "\n",
    "rollouts = rollout.CarRacing_rollouts()\n",
    "\n",
    "states, _, _, _ = rollouts.load_rollout(90)\n",
    "t100 = states[100] * 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "pil_image = Image.fromarray(t100.astype(\"uint8\"))\n",
    "pil_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t100_vae = vae(torch.tensor(t100).permute(2, 0, 1).float().unsqueeze(0) / 255.0*255.0)[0].detach().permute(0, 2, 3, 1).numpy()[0]*255.0\n",
    "t100_vae.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t100_vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pil_image_vae = Image.fromarray(t100_vae.astype(\"uint8\"))\n",
    "pil_image_vae.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rollout\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = rollout.CarRacing_rollouts()\n",
    "seq = cr.get_rollouts(num_rollouts=2, reflesh_rate=20, max_episode=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states, actions, rewards, dones = cr.load_rollout(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s100 = states[0]\n",
    "\n",
    "pil_im = Image.fromarray((s100).astype(\"uint8\"))\n",
    "pil_im.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_seq = states[0]\n",
    "pil_im_seq = Image.fromarray((s_seq).astype(\"uint8\"))\n",
    "pil_im_seq.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.VAE import VAE, loss_function\n",
    "import rollout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset_vae(n, m, idx):\n",
    "    cr = rollout.CarRacing_rollouts()\n",
    "    dataset = np.zeros((n*m, 64, 64, 3))\n",
    "    index = 0\n",
    "    for i in idx:\n",
    "        states, _, _, _ = cr.load_rollout(i)\n",
    "        dataset[index:index+m] = states\n",
    "        index += m\n",
    "    dataset = np.moveaxis(dataset, 3, 1)\n",
    "    np.random.shuffle(dataset)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 10\n",
    "n = 10000\n",
    "m = 300\n",
    "file_list = os.listdir('./data/CarRacing/')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "vae = VAE().to(device)\n",
    "optimizer = torch.optim.Adam(vae.parameters(), lr=0.001)\n",
    "checkpoint_epoch = -1\n",
    "\n",
    "# if os.path.exists('vae.pth'):\n",
    "#     checkpoint = torch.load('vae.pth')\n",
    "#     vae = VAE().to(device)\n",
    "#     vae.load_state_dict(checkpoint['model_state_dict'])\n",
    "#     optimizer = torch.optim.Adam(vae.parameters(), lr=0.001)\n",
    "#     optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "#     for state in optimizer.state.values():\n",
    "#         for k, v in state.items():\n",
    "#             if isinstance(v, torch.Tensor):\n",
    "#                 state[k] = v.to(device)\n",
    "#     checkpoint_epoch = checkpoint['epoch']\n",
    "# else:\n",
    "#     vae = VAE().to(device)\n",
    "#     optimizer = torch.optim.Adam(vae.parameters(), lr=0.001)\n",
    "# del checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if checkpoint_epoch + 1 == num_epochs:\n",
    "    print('already trained')\n",
    "else:\n",
    "    for epoch in range(checkpoint_epoch+1, num_epochs):\n",
    "        dataset_idx = np.array([id for id in range(9000)]).astype(int)\n",
    "        np.random.shuffle(dataset_idx)\n",
    "        for i in range(9000 // batch_size):\n",
    "            dataset = make_dataset_vae(batch_size, m, dataset_idx[i*batch_size:(i+1)*batch_size])\n",
    "            dataset = torch.tensor(dataset).float().to(device)\n",
    "\n",
    "            vae.train()\n",
    "            optimizer.zero_grad()\n",
    "            recon_batch, mu, logvar = vae(dataset)\n",
    "            loss, r_loss, kl_loss = loss_function(recon_batch, dataset, mu, logvar)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (i+1) % 10 == 0:\n",
    "                print('[epoch {}/{}][train {}/{}, test {}/{}], loss: {:.4f}, rmse_loss: {:.4f}, kl_loss: {:.4f}'.format(epoch + 1, num_epochs, i+1, 9000 // batch_size, 0, 1000 // batch_size, loss.item(), r_loss.item(), kl_loss.item()))\n",
    "                print(\"Use Memory: {:.2f} MB\".format(torch.cuda.memory_allocated() / 1024 / 1024))\n",
    "\n",
    "            # GPU memory: remove data\n",
    "            del dataset\n",
    "\n",
    "            if i != 9000 // batch_size - 1:\n",
    "                del loss\n",
    "                del r_loss\n",
    "                del kl_loss\n",
    "        \n",
    "        print(\"save model: epoch {}\".format(epoch + 1))\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': vae.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            }, 'vae.pth')\n",
    "        \n",
    "        del loss\n",
    "        del r_loss\n",
    "        del kl_loss\n",
    "        \n",
    "        vae.eval()\n",
    "        print(\"test: epoch {}\".format(epoch + 1))\n",
    "        with torch.no_grad():\n",
    "            test_idx = np.array([i for i in range(9000, 10000)]).astype(int)\n",
    "            for i in range(1000 // batch_size):\n",
    "                dataset = make_dataset_vae(batch_size, m, test_idx[i*batch_size:(i+1)*batch_size])\n",
    "                dataset = torch.tensor(dataset).float().to(device)\n",
    "\n",
    "                recon_batch, mu, logvar = vae(dataset)\n",
    "                loss, r_loss, kl_loss = loss_function(recon_batch, dataset, mu, logvar)\n",
    "\n",
    "                if (i+1) % 10 == 0:\n",
    "                    print('[epoch {}/{}][train {}/{}, test {}/{}], loss: {:.4f}, rmse_loss: {:.4f}, kl_loss: {:.4f}'.format(epoch + 1, num_epochs, 9000, 9000 // batch_size, i+1, 1000 // batch_size, loss.item(), r_loss.item(), kl_loss.item()))\n",
    "                    print(\"Use Memory: {:.2f} MB\".format(torch.cuda.memory_allocated() / 1024 / 1024))\n",
    "\n",
    "                # GPU memory: remove data\n",
    "                del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.VAE import VAE, loss_function\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "vae = VAE().to(device)\n",
    "optimizer = torch.optim.Adam(vae.parameters(), lr=0.001)\n",
    "checkpoint = torch.load('vae.pth')\n",
    "vae.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "for state in optimizer.state.values():\n",
    "    for k, v in state.items():\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            state[k] = v.to(device)\n",
    "\n",
    "vae.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import rollout\n",
    "\n",
    "rollouts = rollout.CarRacing_rollouts()\n",
    "\n",
    "states, _, _, _ = rollouts.load_rollout(30)\n",
    "t100 = states[100]\n",
    "np.mean(t100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rollouts = rollout.CarRacing_rollouts()\n",
    "\n",
    "states, _, _, _ = rollouts.load_rollout(30)\n",
    "t100 = states[150]\n",
    "t100_255 = t100 * 255.0\n",
    "pil_image = Image.fromarray(t100_255.astype(\"uint8\"))\n",
    "pil_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t100_vae = torch.tensor(t100).float().to(device)\n",
    "t100_vae = t100_vae.permute(2, 0, 1).unsqueeze(0)\n",
    "t100_vae.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t100_vae = vae(t100_vae)[0].squeeze(0).permute(1, 2, 0).cpu().detach().numpy()\n",
    "t100_vae.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t100_vae_255 = t100_vae * 255.0\n",
    "pil_image = Image.fromarray(t100_vae_255.astype(\"uint8\"))\n",
    "pil_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_z = torch.randn(1, 32).to(device)\n",
    "random_z[0][0] = 1.0\n",
    "random_z[0][1] = 1.0\n",
    "random_z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_im = vae.decode(random_z).squeeze(0).permute(1, 2, 0).cpu().detach().numpy()\n",
    "rand_im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_im_255 = rand_im * 255.0\n",
    "pil_image = Image.fromarray(rand_im_255.astype(\"uint8\"))\n",
    "pil_image.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## im to z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.VAE import VAE\n",
    "import rollout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = rollout.CarRacing_rollouts()\n",
    "cr.rollout_to_z()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.MDN_RNN import MDNRNN, loss_func\n",
    "import rollout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset_rnn(n, m, idx, use_reward=False, use_Done=False):\n",
    "    cr = rollout.CarRacing_rollouts()\n",
    "    Z = np.zeros((n, m, 32)) # (batch, seq, dim)\n",
    "    A = np.zeros((n, m, 3)) # (batch, seq, dim)\n",
    "    Reward = np.zeros((n, m, 1)) # (batch, seq, dim)\n",
    "    Done = np.zeros((n, m, 1)) # (batch, seq, dim)\n",
    "    for i, j in enumerate(idx):\n",
    "        z, _, _, action, reward, _ = cr.load_rollout_z(j)\n",
    "        Z[i] = z\n",
    "        A[i] = action\n",
    "        if use_reward:\n",
    "            Reward[i] = reward\n",
    "        if use_Done:\n",
    "            Done[i] = done\n",
    "\n",
    "    # Z = np.moveaxis(Z, 1, 0)\n",
    "    # A = np.moveaxis(A, 1, 0)\n",
    "    # if use_reward:\n",
    "    #     Reward = np.moveaxis(Reward, 1, 0)\n",
    "    # if use_Done:\n",
    "    #     Done = np.moveaxis(Done, 1, 0)\n",
    "    \n",
    "    return Z, A, Reward, Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z, A, Reward, Done = make_dataset_rnn(3, 300, [0, 1, 2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 300, 32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 300, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 10\n",
    "n = 10000\n",
    "m = 300\n",
    "file_list = os.listdir('./data_z/')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "mdnrnn = MDNRNN().to(device)\n",
    "optimizer = torch.optim.Adam(mdnrnn.parameters(), lr=0.00001)\n",
    "checkpoint_epoch = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 300, 35)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z, A, _, _ = make_dataset_rnn(batch_size, m, dataset_idx[i*batch_size:(i+1)*batch_size], use_reward=False, use_Done=False)\n",
    "za = np.concatenate((Z, A), axis=2)\n",
    "za.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [10/900], Loss: 47.8597\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [20/900], Loss: 44.1331\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [30/900], Loss: 46.7708\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [40/900], Loss: 46.0268\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [50/900], Loss: 44.4028\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [60/900], Loss: 44.2158\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [70/900], Loss: 47.8136\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [80/900], Loss: 43.2188\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [90/900], Loss: 44.8604\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [100/900], Loss: 45.3640\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [110/900], Loss: 43.6904\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [120/900], Loss: 44.5207\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [130/900], Loss: 46.5964\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [140/900], Loss: 45.4753\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [150/900], Loss: 42.9159\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [160/900], Loss: 44.9637\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [170/900], Loss: 43.3143\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [180/900], Loss: 44.1974\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [190/900], Loss: 44.5109\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [200/900], Loss: 43.9684\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [210/900], Loss: 43.7359\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [220/900], Loss: 44.2446\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [230/900], Loss: 43.4643\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [240/900], Loss: 45.4802\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [250/900], Loss: 42.5483\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [260/900], Loss: 42.5033\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [270/900], Loss: 43.7632\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [280/900], Loss: 45.5934\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [290/900], Loss: 43.1529\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [300/900], Loss: 45.1155\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [310/900], Loss: 44.4877\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [320/900], Loss: 43.1552\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [330/900], Loss: 44.0790\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [340/900], Loss: 42.5379\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [350/900], Loss: 42.2378\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [360/900], Loss: 43.6592\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [370/900], Loss: 42.8785\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [380/900], Loss: 42.2472\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [390/900], Loss: 42.0492\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [400/900], Loss: 43.5024\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [410/900], Loss: 43.5986\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [420/900], Loss: 38.5236\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [430/900], Loss: 38.8159\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [440/900], Loss: 39.2504\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [450/900], Loss: 32.6388\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [460/900], Loss: 31.8721\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [470/900], Loss: 26.4570\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [480/900], Loss: 18.9181\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [490/900], Loss: 15.9478\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [500/900], Loss: 13.4802\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [510/900], Loss: 5.1072\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [520/900], Loss: 5.3691\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [530/900], Loss: 4.1827\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [540/900], Loss: -1.9912\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [550/900], Loss: -0.8988\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [560/900], Loss: -1.9115\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [570/900], Loss: -7.5950\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [580/900], Loss: -7.2372\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [590/900], Loss: -13.9293\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [600/900], Loss: -14.1245\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [610/900], Loss: -14.8164\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [620/900], Loss: -16.9277\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [630/900], Loss: -17.3494\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [640/900], Loss: -19.5386\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [650/900], Loss: -20.5994\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [660/900], Loss: -21.1645\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [670/900], Loss: -23.8488\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [680/900], Loss: -24.6779\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [690/900], Loss: -22.5178\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [700/900], Loss: -27.5058\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [710/900], Loss: -30.9933\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [720/900], Loss: -28.3468\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [730/900], Loss: -25.8064\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [740/900], Loss: -33.8066\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [750/900], Loss: -28.6440\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [760/900], Loss: -27.9116\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [770/900], Loss: -31.8043\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [780/900], Loss: -33.2691\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [790/900], Loss: -30.3620\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [800/900], Loss: -32.0306\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [810/900], Loss: -38.1035\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [820/900], Loss: -33.4044\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [830/900], Loss: -34.9977\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [840/900], Loss: -36.9278\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [850/900], Loss: -34.4987\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [860/900], Loss: -40.9319\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [870/900], Loss: -40.1627\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [880/900], Loss: -40.2371\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [890/900], Loss: -42.6895\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [900/900], Loss: -42.5427\n",
      "Use Memory: 28.09 MB\n",
      "save model: epoch 1\n",
      "test: epoch 1\n",
      "Epoch [1/10], Step [10/100], Loss: -40.1007\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [20/100], Loss: -40.6198\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [30/100], Loss: -40.1890\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [40/100], Loss: -45.7418\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [50/100], Loss: -43.5638\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [60/100], Loss: -41.7710\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [70/100], Loss: -40.8917\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [80/100], Loss: -38.8709\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [90/100], Loss: -40.0005\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [1/10], Step [100/100], Loss: -37.0745\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [10/900], Loss: -40.1286\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [20/900], Loss: -40.1321\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [30/900], Loss: -42.2738\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [40/900], Loss: -39.8363\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [50/900], Loss: -41.5631\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [60/900], Loss: -44.8367\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [70/900], Loss: -40.5159\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [80/900], Loss: -41.1056\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [90/900], Loss: -43.6773\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [100/900], Loss: -46.3753\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [110/900], Loss: -47.9026\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [120/900], Loss: -50.3638\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [130/900], Loss: -46.3440\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [140/900], Loss: -46.2930\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [150/900], Loss: -44.8024\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [160/900], Loss: -46.5166\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [170/900], Loss: -46.4429\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [180/900], Loss: -53.1481\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [190/900], Loss: -48.7550\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [200/900], Loss: -49.4841\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [210/900], Loss: -52.3003\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [220/900], Loss: -51.7115\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [230/900], Loss: -50.8804\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [240/900], Loss: -47.9074\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [250/900], Loss: -52.3484\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [260/900], Loss: -53.2186\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [270/900], Loss: -43.5350\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [280/900], Loss: -48.3750\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [290/900], Loss: -49.8009\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [300/900], Loss: -51.7205\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [310/900], Loss: -53.1000\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [320/900], Loss: -51.9805\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [330/900], Loss: -55.4772\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [340/900], Loss: -54.3277\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [350/900], Loss: -55.5666\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [360/900], Loss: -55.8448\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [370/900], Loss: -52.4737\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [380/900], Loss: -54.9241\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [390/900], Loss: -56.4144\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [400/900], Loss: -48.0094\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [410/900], Loss: -55.7290\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [420/900], Loss: -58.9864\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [430/900], Loss: -56.1055\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [440/900], Loss: -54.5215\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [450/900], Loss: -56.1615\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [460/900], Loss: -55.6393\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [470/900], Loss: -55.6596\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [480/900], Loss: -59.8658\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [490/900], Loss: -59.3126\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [500/900], Loss: -50.9627\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [510/900], Loss: -56.6615\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [520/900], Loss: -47.0384\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [530/900], Loss: -57.8122\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [540/900], Loss: -57.4154\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [550/900], Loss: -56.1905\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [560/900], Loss: -54.9728\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [570/900], Loss: -55.6496\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [580/900], Loss: -57.8057\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [590/900], Loss: -59.2858\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [600/900], Loss: -57.7930\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [610/900], Loss: -51.7973\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [620/900], Loss: -52.6084\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [630/900], Loss: -57.8694\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [640/900], Loss: -60.1877\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [650/900], Loss: -56.9646\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [660/900], Loss: -58.6127\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [670/900], Loss: -54.2177\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [680/900], Loss: -55.2779\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [690/900], Loss: -59.2288\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [700/900], Loss: -60.1957\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [710/900], Loss: -56.6795\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [720/900], Loss: -55.3678\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [730/900], Loss: -55.5850\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [740/900], Loss: -57.7190\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [750/900], Loss: -59.5739\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [760/900], Loss: -54.7954\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [770/900], Loss: -58.9568\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [780/900], Loss: -51.6128\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [790/900], Loss: -49.6839\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [800/900], Loss: -55.2645\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [810/900], Loss: -58.9804\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [820/900], Loss: -58.1822\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [830/900], Loss: -59.6602\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [840/900], Loss: -59.2011\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [850/900], Loss: -55.4988\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [860/900], Loss: -54.1770\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [870/900], Loss: -56.1696\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [880/900], Loss: -60.0801\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [890/900], Loss: -63.6676\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [900/900], Loss: -62.1769\n",
      "Use Memory: 28.09 MB\n",
      "save model: epoch 2\n",
      "test: epoch 2\n",
      "Epoch [2/10], Step [10/100], Loss: -56.6409\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [20/100], Loss: -57.6751\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [30/100], Loss: -56.9373\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [40/100], Loss: -63.6941\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [50/100], Loss: -62.0628\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [60/100], Loss: -59.4463\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [70/100], Loss: -57.3182\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [80/100], Loss: -56.3628\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [90/100], Loss: -58.2061\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [2/10], Step [100/100], Loss: -52.6267\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [10/900], Loss: -59.8090\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [20/900], Loss: -59.9816\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [30/900], Loss: -51.7389\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [40/900], Loss: -59.3620\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [50/900], Loss: -48.5446\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [60/900], Loss: -55.1330\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [70/900], Loss: -54.2954\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [80/900], Loss: -58.6665\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [90/900], Loss: -57.1391\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [100/900], Loss: -55.5738\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [110/900], Loss: -59.9120\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [120/900], Loss: -58.0724\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [130/900], Loss: -58.0331\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [140/900], Loss: -54.9843\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [150/900], Loss: -57.9802\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [160/900], Loss: -51.6675\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [170/900], Loss: -61.3825\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [180/900], Loss: -60.5994\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [190/900], Loss: -55.6105\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [200/900], Loss: -56.4822\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [210/900], Loss: -57.0895\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [220/900], Loss: -57.0317\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [230/900], Loss: -60.1417\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [240/900], Loss: -52.4741\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [250/900], Loss: -60.7585\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [260/900], Loss: -57.0000\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [270/900], Loss: -60.7508\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [280/900], Loss: -63.0122\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [290/900], Loss: -57.3528\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [300/900], Loss: -58.4716\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [310/900], Loss: -62.9919\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [320/900], Loss: -62.4474\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [330/900], Loss: -54.7391\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [340/900], Loss: -54.2563\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [350/900], Loss: -57.9483\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [360/900], Loss: -59.2488\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [370/900], Loss: -55.9381\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [380/900], Loss: -64.2115\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [390/900], Loss: -60.4216\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [400/900], Loss: -55.1020\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [410/900], Loss: -51.7709\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [420/900], Loss: -56.5968\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [430/900], Loss: -57.3980\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [440/900], Loss: -58.4912\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [450/900], Loss: -64.2635\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [460/900], Loss: -55.3957\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [470/900], Loss: -59.9664\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [480/900], Loss: -61.0061\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [490/900], Loss: -60.5416\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [500/900], Loss: -58.2162\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [510/900], Loss: -62.8568\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [520/900], Loss: -56.3166\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [530/900], Loss: -59.7838\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [540/900], Loss: -60.3424\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [550/900], Loss: -49.9890\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [560/900], Loss: -54.2212\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [570/900], Loss: -60.9225\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [580/900], Loss: -58.9277\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [590/900], Loss: -62.3412\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [600/900], Loss: -61.7280\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [610/900], Loss: -64.6750\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [620/900], Loss: -62.5041\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [630/900], Loss: -56.5642\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [640/900], Loss: -55.0477\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [650/900], Loss: -63.8339\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [660/900], Loss: -55.1307\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [670/900], Loss: -55.6234\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [680/900], Loss: -65.5576\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [690/900], Loss: -65.5627\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [700/900], Loss: -54.3122\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [710/900], Loss: -58.7534\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [720/900], Loss: -60.8909\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [730/900], Loss: -57.2695\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [740/900], Loss: -58.7327\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [750/900], Loss: -58.2447\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [760/900], Loss: -59.9109\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [770/900], Loss: -57.2957\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [780/900], Loss: -54.4074\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [790/900], Loss: -63.1648\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [800/900], Loss: -51.3028\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [810/900], Loss: -53.1030\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [820/900], Loss: -57.8343\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [830/900], Loss: -58.7405\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [840/900], Loss: -60.6727\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [850/900], Loss: -58.0159\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [860/900], Loss: -63.7952\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [870/900], Loss: -55.4884\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [880/900], Loss: -61.9011\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [890/900], Loss: -63.6674\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [900/900], Loss: -63.8317\n",
      "Use Memory: 28.09 MB\n",
      "save model: epoch 3\n",
      "test: epoch 3\n",
      "Epoch [3/10], Step [10/100], Loss: -57.8372\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [20/100], Loss: -59.2961\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [30/100], Loss: -59.1689\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [40/100], Loss: -66.1222\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [50/100], Loss: -64.3014\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [60/100], Loss: -60.7884\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [70/100], Loss: -59.5704\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [80/100], Loss: -56.3273\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [90/100], Loss: -58.5298\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [3/10], Step [100/100], Loss: -54.4434\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [10/900], Loss: -59.4115\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [20/900], Loss: -57.1514\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [30/900], Loss: -62.2301\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [40/900], Loss: -51.9050\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [50/900], Loss: -49.3254\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [60/900], Loss: -58.4319\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [70/900], Loss: -59.7295\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [80/900], Loss: -59.7765\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [90/900], Loss: -58.6951\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [100/900], Loss: -58.3110\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [110/900], Loss: -62.5539\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [120/900], Loss: -55.7585\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [130/900], Loss: -57.6658\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [140/900], Loss: -60.3927\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [150/900], Loss: -60.4849\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [160/900], Loss: -62.3681\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [170/900], Loss: -58.4690\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [180/900], Loss: -60.4161\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [190/900], Loss: -54.2750\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [200/900], Loss: -59.8701\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [210/900], Loss: -61.9754\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [220/900], Loss: -61.0843\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [230/900], Loss: -58.5005\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [240/900], Loss: -61.8565\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [250/900], Loss: -60.8311\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [260/900], Loss: -56.7280\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [270/900], Loss: -54.0563\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [280/900], Loss: -60.5240\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [290/900], Loss: -52.3703\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [300/900], Loss: -64.6437\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [310/900], Loss: -58.1873\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [320/900], Loss: -56.8028\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [330/900], Loss: -57.5849\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [340/900], Loss: -57.5969\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [350/900], Loss: -61.4575\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [360/900], Loss: -58.0452\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [370/900], Loss: -56.3444\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [380/900], Loss: -57.5127\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [390/900], Loss: -60.1404\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [400/900], Loss: -60.7294\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [410/900], Loss: -50.9506\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [420/900], Loss: -53.1083\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [430/900], Loss: -60.6551\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [440/900], Loss: -56.4205\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [450/900], Loss: -61.8992\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [460/900], Loss: -55.6157\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [470/900], Loss: -63.9368\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [480/900], Loss: -60.4377\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [490/900], Loss: -63.0393\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [500/900], Loss: -51.9810\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [510/900], Loss: -58.7843\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [520/900], Loss: -61.6118\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [530/900], Loss: -60.9981\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [540/900], Loss: -53.0281\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [550/900], Loss: -55.8812\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [560/900], Loss: -65.6569\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [570/900], Loss: -64.4295\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [580/900], Loss: -63.2661\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [590/900], Loss: -54.7999\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [600/900], Loss: -63.3657\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [610/900], Loss: -58.4465\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [620/900], Loss: -60.6403\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [630/900], Loss: -59.9714\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [640/900], Loss: -62.6865\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [650/900], Loss: -52.4451\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [660/900], Loss: -64.4389\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [670/900], Loss: -58.2982\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [680/900], Loss: -52.8078\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [690/900], Loss: -62.3038\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [700/900], Loss: -67.3476\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [710/900], Loss: -60.8643\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [720/900], Loss: -55.7095\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [730/900], Loss: -60.3042\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [740/900], Loss: -61.3915\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [750/900], Loss: -62.9576\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [760/900], Loss: -60.4547\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [770/900], Loss: -56.8550\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [780/900], Loss: -59.5496\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [790/900], Loss: -63.2973\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [800/900], Loss: -60.1883\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [810/900], Loss: -57.8928\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [820/900], Loss: -59.7218\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [830/900], Loss: -65.4994\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [840/900], Loss: -64.8955\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [850/900], Loss: -54.0531\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [860/900], Loss: -58.5610\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [870/900], Loss: -60.0450\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [880/900], Loss: -59.9280\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [890/900], Loss: -50.6496\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [900/900], Loss: -57.3486\n",
      "Use Memory: 28.09 MB\n",
      "save model: epoch 4\n",
      "test: epoch 4\n",
      "Epoch [4/10], Step [10/100], Loss: -59.2282\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [20/100], Loss: -59.4247\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [30/100], Loss: -59.8376\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [40/100], Loss: -66.3241\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [50/100], Loss: -64.6975\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [60/100], Loss: -61.5748\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [70/100], Loss: -59.5108\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [80/100], Loss: -56.5727\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [90/100], Loss: -58.4705\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [4/10], Step [100/100], Loss: -54.4655\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [5/10], Step [10/900], Loss: -61.4514\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [5/10], Step [20/900], Loss: -62.3852\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [5/10], Step [30/900], Loss: -57.1698\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [5/10], Step [40/900], Loss: -57.1926\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [5/10], Step [50/900], Loss: -64.5871\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [5/10], Step [60/900], Loss: -52.4071\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [5/10], Step [70/900], Loss: -61.5742\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [5/10], Step [80/900], Loss: -61.3459\n",
      "Use Memory: 28.09 MB\n",
      "Epoch [5/10], Step [90/900], Loss: -62.6274\n",
      "Use Memory: 28.09 MB\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mshuffle(dataset_idx)\n\u001b[0;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m9000\u001b[39m \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m batch_size):\n\u001b[1;32m----> 8\u001b[0m     Z, A, _, _ \u001b[39m=\u001b[39m make_dataset_rnn(batch_size, m, dataset_idx[i\u001b[39m*\u001b[39;49mbatch_size:(i\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m*\u001b[39;49mbatch_size], use_reward\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, use_Done\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m      9\u001b[0m     Z \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(Z)\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     10\u001b[0m     A \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(A)\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mto(device)\n",
      "Cell \u001b[1;32mIn[5], line 8\u001b[0m, in \u001b[0;36mmake_dataset_rnn\u001b[1;34m(n, m, idx, use_reward, use_Done)\u001b[0m\n\u001b[0;32m      6\u001b[0m Done \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((n, m, \u001b[39m1\u001b[39m)) \u001b[39m# (batch, seq, dim)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m i, j \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(idx):\n\u001b[1;32m----> 8\u001b[0m     z, _, _, action, reward, _ \u001b[39m=\u001b[39m cr\u001b[39m.\u001b[39;49mload_rollout_z(j)\n\u001b[0;32m      9\u001b[0m     Z[i] \u001b[39m=\u001b[39m z\n\u001b[0;32m     10\u001b[0m     A[i] \u001b[39m=\u001b[39m action\n",
      "File \u001b[1;32mc:\\Users\\daiki\\Documents\\world_models\\rollout.py:55\u001b[0m, in \u001b[0;36mCarRacing_rollouts.load_rollout_z\u001b[1;34m(self, idx_rolloout)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_rollout_z\u001b[39m(\u001b[39mself\u001b[39m, idx_rolloout):\n\u001b[1;32m---> 55\u001b[0m     data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mload(\u001b[39m\"\u001b[39;49m\u001b[39m./data_z/rollout_z_\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m.npz\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mformat(idx_rolloout))\n\u001b[0;32m     56\u001b[0m     \u001b[39mreturn\u001b[39;00m data[\u001b[39m'\u001b[39m\u001b[39mz\u001b[39m\u001b[39m'\u001b[39m], data[\u001b[39m'\u001b[39m\u001b[39mmu\u001b[39m\u001b[39m'\u001b[39m], data[\u001b[39m'\u001b[39m\u001b[39mlogvar\u001b[39m\u001b[39m'\u001b[39m], data[\u001b[39m'\u001b[39m\u001b[39maction\u001b[39m\u001b[39m'\u001b[39m], data[\u001b[39m'\u001b[39m\u001b[39mreward\u001b[39m\u001b[39m'\u001b[39m], data[\u001b[39m'\u001b[39m\u001b[39mdone\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\daiki\\miniconda3\\envs\\env_torch_world_models\\lib\\site-packages\\numpy\\lib\\npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    425\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 427\u001b[0m     fid \u001b[39m=\u001b[39m stack\u001b[39m.\u001b[39menter_context(\u001b[39mopen\u001b[39;49m(os_fspath(file), \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[0;32m    428\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    430\u001b[0m \u001b[39m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if checkpoint_epoch + 1 == num_epochs:\n",
    "    print('already trained')\n",
    "else:\n",
    "    for epoch in range(checkpoint_epoch+1, num_epochs):\n",
    "        dataset_idx = np.array([id for id in range(9000)]).astype(int)\n",
    "        np.random.shuffle(dataset_idx)\n",
    "        for i in range(9000 // batch_size):\n",
    "            Z, A, _, _ = make_dataset_rnn(batch_size, m, dataset_idx[i*batch_size:(i+1)*batch_size], use_reward=False, use_Done=False)\n",
    "            Z = torch.tensor(Z).float().to(device)\n",
    "            A = torch.tensor(A).float().to(device)\n",
    "            H0 = torch.zeros(1, 9, 256).float().to(device)\n",
    "            C0 = torch.zeros(1, 9, 256).float().to(device)\n",
    "\n",
    "            in_Z = Z[:-1]\n",
    "            out_Z = Z[1:]\n",
    "            A = A[:-1]\n",
    "\n",
    "            mdnrnn.train()\n",
    "            optimizer.zero_grad()\n",
    "            # mdn_out, hidden, cell = mdnrnn(A, in_Z, H0, C0)\n",
    "            pi, mu, logsigma, hidden, cell = mdnrnn(A, in_Z, H0, C0)\n",
    "            loss = loss_func(out_Z, pi, mu, logsigma)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (i+1) % 10 == 0:\n",
    "                print(\"Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}\".format(epoch+1, num_epochs, i+1, 9000 // batch_size, loss.item()))\n",
    "                print(\"Use Memory: {:.2f} MB\".format(torch.cuda.memory_allocated() / 1024 / 1024))\n",
    "\n",
    "            # GPU memory: remove data\n",
    "            del Z, A, H0, C0, in_Z, out_Z, pi, mu, logsigma, hidden, cell\n",
    "\n",
    "            if i != 9000 // batch_size - 1:\n",
    "                del loss\n",
    "        \n",
    "        print(\"save model: epoch {}\".format(epoch + 1))\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': mdnrnn.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            }, 'mdnrnn.pth')\n",
    "        \n",
    "        del loss\n",
    "\n",
    "        mdnrnn.eval()\n",
    "        print(\"test: epoch {}\".format(epoch + 1))\n",
    "        with torch.no_grad():\n",
    "            test_idx = np.array([i for i in range(9000, 10000)]).astype(int)\n",
    "            for i in range(1000 // batch_size):\n",
    "                Z, A, _, _ = make_dataset_rnn(batch_size, m, test_idx[i*batch_size:(i+1)*batch_size], use_reward=False, use_Done=False)\n",
    "                Z = torch.tensor(Z).float().to(device)\n",
    "                A = torch.tensor(A).float().to(device)\n",
    "                H0 = torch.zeros(1, 9, 256).float().to(device)\n",
    "                C0 = torch.zeros(1, 9, 256).float().to(device)\n",
    "\n",
    "                in_Z = Z[:-1]\n",
    "                out_Z = Z[1:]\n",
    "                A = A[:-1]\n",
    "\n",
    "                pi, mu, logsigma, hidden, cell = mdnrnn(A, in_Z, H0, C0)\n",
    "                loss = loss_func(out_Z, pi, mu, logsigma)\n",
    "\n",
    "                if (i+1) % 10 == 0:\n",
    "                    print(\"Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}\".format(epoch+1, num_epochs, i+1, 1000 // batch_size, loss.item()))\n",
    "                    print(\"Use Memory: {:.2f} MB\".format(torch.cuda.memory_allocated() / 1024 / 1024))\n",
    "\n",
    "                # GPU memory: remove data\n",
    "                del Z, A, H0, C0, in_Z, out_Z, pi, mu, logsigma, hidden, cell, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 300, 160])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MDN-RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    \"\"\"LSTM\"\"\"\n",
    "    def __init__(self, z_size=32, a_size=3, hidden_size=256, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.z_size = z_size\n",
    "        self.a_size = a_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(z_size + a_size, hidden_size, num_layers, batch_first=True)\n",
    "    \n",
    "    def forward(self, z, a, hidden, cell):\n",
    "        input = torch.cat((z, a), dim=2)\n",
    "        output, (hidden, cell) = self.lstm(input, (hidden, cell))\n",
    "        return output, hidden, cell\n",
    "\n",
    "lstm = LSTM().to(device)\n",
    "lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MDN(nn.Module):\n",
    "    \"\"\"Mixtures Density Network\"\"\"\n",
    "    def __init__(self, z_size=32, hidden_size=256, num_layers=1, num_mixtures=5, use_reward=False, use_Done=False):\n",
    "        super().__init__()\n",
    "        self.z_size = z_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.num_mixtures = num_mixtures\n",
    "        self.use_reward = use_reward\n",
    "        self.use_Done = use_Done\n",
    "\n",
    "        if use_reward and use_Done:\n",
    "            self.output_size = 3 * num_mixtures * z_size + 2\n",
    "        elif use_reward or use_Done:\n",
    "            self.output_size = 3 * num_mixtures * z_size + 1\n",
    "        else:\n",
    "            self.output_size = 3 * num_mixtures * z_size\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size, self.output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        output = self.fc(x)\n",
    "        return output\n",
    "        # if self.use_reward and self.use_Done:\n",
    "        #     pi, mu, logsigma, reward, done = self.get_mixture(output)\n",
    "        #     return pi, mu, logsigma, reward, done\n",
    "        # elif self.use_reward or self.use_Done:\n",
    "        #     pi, mu, logsigma, reward_done = self.get_mixture(output)\n",
    "        #     return pi, mu, logsigma, reward_done\n",
    "        # else:\n",
    "        #     pi, mu, logsigma = self.get_mixture(output)\n",
    "        #     return pi, mu, logsigma\n",
    "    \n",
    "    def get_mixture(self, output):\n",
    "        pi = output[:, :, :self.num_mixtures]\n",
    "        mu = output[:, :, self.num_mixtures:2*self.num_mixtures]\n",
    "        logsigma = output[:, :, 2*self.num_mixtures:3*self.num_mixtures]\n",
    "\n",
    "        if self.use_reward and self.use_Done:\n",
    "            reward = output[:, :, 3*self.num_mixtures]\n",
    "            done = output[:, :, 3*self.num_mixtures+1]\n",
    "            return pi, mu, logsigma, reward, done\n",
    "        elif self.use_reward or self.use_Done:\n",
    "            reward_done = output[:, :, 3*self.num_mixtures]\n",
    "            return pi, mu, logsigma, reward_done\n",
    "        else:\n",
    "            return pi, mu, logsigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MDNRNN(nn.Module):\n",
    "    \"\"\"MDN-RNN\"\"\"\n",
    "    def __init__(self, z_size=32, a_size=3, hidden_size=256, num_layers=1, num_mixtures=5, use_reward=False, use_Done=False):\n",
    "        super().__init__()\n",
    "        self.z_size = z_size\n",
    "        self.a_size = a_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.num_mixtures = num_mixtures\n",
    "        self.use_reward = use_reward\n",
    "        self.use_Done = use_Done\n",
    "\n",
    "        self.lstm = LSTM(z_size, a_size, hidden_size, num_layers)\n",
    "        self.mdn = MDN(z_size, hidden_size, num_layers, num_mixtures, use_reward, use_Done)\n",
    "    \n",
    "    def forward(self, z, a, hidden, cell):\n",
    "        output, hidden, cell = self.lstm(z, a, hidden, cell)\n",
    "        # pi, mu, logsigma = self.mdn(output)\n",
    "        output = self.mdn(output)\n",
    "        # return pi, mu, logsigma, hidden, cell\n",
    "        return output, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(MDNRNN().to(device), [(1, 1, 32), (1, 1, 3), (1, 1, 256), (1, 1, 256)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def loss_func(y_true, pi, mu, logsigma):\n",
    "    \"\"\"MDN Loss Function\n",
    "    \n",
    "    y_true: (seq_len, batch_size, z_size)\n",
    "    pi: (seq_len, batch_size, num_mixtures)\n",
    "    mu: (seq_len, batch_size, num_mixtures * z_size)\n",
    "    \"\"\"\n",
    "    pi = pi - torch.max(pi, dim=2, keepdim=True)[0]\n",
    "\n",
    "    log_softmax_pi = torch.log_softmax(pi, dim=2)\n",
    "    log_gauss = -0.5 * (2 * logsigma + math.log(2 * math.pi) + torch.pow(y_true - mu, 2) / torch.exp(2 * logsigma))\n",
    "\n",
    "    loss = torch.sum(torch.exp(log_softmax_pi + log_gauss), dim=2, keepdim=True)\n",
    "    # log0 対策\n",
    "    loss = torch.maximum(loss, torch.tensor(1e-10).to(device))\n",
    "    loss = -torch.log(loss)\n",
    "    loss = torch.mean(loss)\n",
    "    return loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conoller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Controller:\n",
    "    \"\"\"Controller\"\"\"\n",
    "    def __init__(self, z_size, a_size, h_size, params):\n",
    "        self.z_size = z_size\n",
    "        self.a_size = a_size\n",
    "        self.h_size = h_size\n",
    "\n",
    "        self.input_size = z_size + h_size\n",
    "\n",
    "        self.bias = np.array(params[:self.a_size])\n",
    "        self.weight = np.array(params[self.a_size:]).reshape(self.input_size, self.a_size)\n",
    "\n",
    "    def forward(self, z, h):\n",
    "        input = np.concatenate((z, h), axis=0)\n",
    "        # print(input.shape, self.weight.shape, self.bias.shape)\n",
    "        a = np.dot(self.weight.T, input) + self.bias\n",
    "        a = np.tanh(a)\n",
    "        a[1] = (a[1] + 1.0) / 2.0\n",
    "        a[2] = np.minimum(np.maximum(a[2], 0), 1.0)\n",
    "        return a\n",
    "    \n",
    "def get_random_params(z_size, a_size, h_size, sigma):\n",
    "    \"\"\"ランダムなパラメータを生成\"\"\"\n",
    "    params_size = (z_size + h_size) * a_size + a_size\n",
    "    return np.random.standard_cauchy(params_size) * sigma\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.VAE import VAE\n",
    "from models.MDN_RNN import MDNRNN\n",
    "from gym.envs.box2d.car_dynamics import Car\n",
    "import es as ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32_w,64)-aCMA-ES (mu_w=17.6,w_1=11%) in dimension 867 (seed=195014, Mon Jun 19 11:37:32 2023)\n"
     ]
    }
   ],
   "source": [
    "z_size = 32\n",
    "a_size = 3\n",
    "h_size = 256\n",
    "\n",
    "params_size = (z_size + h_size) * a_size + a_size\n",
    "\n",
    "es = ES.CMAES(params_size, 0.1, 64)\n",
    "rewards_through_gens = []\n",
    "generation = 1\n",
    "\n",
    "def reshape_state(state):\n",
    "    HEIGHT = 64\n",
    "    WIDTH = 64\n",
    "    state = state[0:84, :, :]\n",
    "    state = np.array(Image.fromarray(state).resize((HEIGHT, WIDTH)))\n",
    "    state = state / 255.0\n",
    "    return state\n",
    "\n",
    "def decide_action(v, m, c, state, hidden, cell, device, use_world_model=False):\n",
    "    hidden = hidden.reshape(-1)\n",
    "    cell = cell.reshape(-1)\n",
    "\n",
    "    state = reshape_state(state)\n",
    "    state = np.moveaxis(state, 2, 0)\n",
    "    state = np.reshape(state, (-1, 3, 64, 64))\n",
    "    state = torch.tensor(state, dtype=torch.float32).to(device)\n",
    "    z, _, _ = v.encode(state)\n",
    "    z = z.detach().numpy()\n",
    "    z = z.reshape(-1)\n",
    "    a = c.forward(z, hidden)\n",
    "    z = torch.tensor(z, dtype=torch.float32).to(device).reshape(1, 1, -1)\n",
    "    a = torch.tensor(a, dtype=torch.float32).to(device).reshape(1, 1, -1)\n",
    "    hidden = torch.tensor(hidden, dtype=torch.float32).to(device).reshape(1, 1, -1)\n",
    "    cell = torch.tensor(cell, dtype=torch.float32).to(device).reshape(1, 1, -1)\n",
    "    pi, mu, logsigma, next_hidden, next_cell = m(z, a, hidden, cell)\n",
    "\n",
    "    pi, mu, logsigma = pi.detach().numpy().reshape(-1), mu.detach().numpy().reshape(-1), logsigma.detach().numpy().reshape(-1)\n",
    "    next_hidden, next_cell = next_hidden.detach().numpy().reshape(-1), next_cell.detach().numpy().reshape(-1)\n",
    "    a = a.detach().numpy().reshape(-1)\n",
    "    if use_world_model:\n",
    "        return a, pi, mu, logsigma, next_hidden, next_cell\n",
    "    else:\n",
    "        return a, next_hidden, next_cell\n",
    "\n",
    "def play(params, seed_num=0):\n",
    "    with torch.no_grad():\n",
    "        device = torch.device('cpu')\n",
    "        vae = VAE()\n",
    "        checkpoint = torch.load('vae.pth')\n",
    "        vae.load_state_dict(checkpoint['model_state_dict'])\n",
    "        vae = vae.eval()\n",
    "        vae.to(device)\n",
    "\n",
    "        mdnrnn = MDNRNN().to(device)\n",
    "        checkpoint = torch.load('mdnrnn.pth')\n",
    "        mdnrnn.load_state_dict(checkpoint['model_state_dict'])\n",
    "        mdnrnn = mdnrnn.eval()\n",
    "        mdnrnn.to(device)\n",
    "\n",
    "        controller = Controller(z_size, a_size, h_size, params)\n",
    "\n",
    "        env = gym.make('CarRacing-v2', render_mode='rgb_array', domain_randomize=True)\n",
    "        env.reset(seed=seed_num)\n",
    "\n",
    "        _NUM_TRIALS = 16\n",
    "        agent_reward = 0\n",
    "\n",
    "        for trial in range(_NUM_TRIALS):\n",
    "            state, _ = env.reset()\n",
    "            np.random.seed(int(str(time.time()*1000000)[10:13]))\n",
    "            position = np.random.randint(len(env.track))\n",
    "            env.car = Car(env.world, *env.track[position][1:4])\n",
    "\n",
    "            hidden = torch.zeros(1, 1, 256).float().to(device)\n",
    "            cell = torch.zeros(1, 1, 256).float().to(device)\n",
    "\n",
    "            total_reward = 0.0\n",
    "            steps = 0\n",
    "\n",
    "            while True:\n",
    "                action, hidden, cell = decide_action(vae, mdnrnn, controller, state, hidden, cell, device)\n",
    "                state, reward, _, _, _ = env.step(action)\n",
    "                total_reward += reward\n",
    "                steps += 1\n",
    "                if steps == 999:\n",
    "                    break\n",
    "            \n",
    "            total_reward = np.maximum(-100, total_reward)\n",
    "            agent_reward += total_reward\n",
    "        \n",
    "        env.close()\n",
    "        return -(agent_reward / _NUM_TRIALS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-19 14:19:36,425] A new study created in memory with name: no-name-57c2839d-6ced-46d0-b993-af902651d385\n",
      "[I 2023-06-19 14:24:39,838] Trial 0 finished with value: 73.16343157057685 and parameters: {'param_0': -1.3751825023676032, 'param_1': -0.3715924696282644, 'param_2': -0.7085217400454584, 'param_3': 0.6938858257767611, 'param_4': -1.8558572641929585, 'param_5': -1.2342172512885998, 'param_6': -0.8633973906365511, 'param_7': 1.3860189825935731, 'param_8': 1.0887450946533548, 'param_9': -0.9118907200055362, 'param_10': -1.7431373308346494, 'param_11': 1.371681827961586, 'param_12': 1.5325121586470498, 'param_13': 0.9796971891184412, 'param_14': 1.4725648474513973, 'param_15': 0.6163735192358852, 'param_16': -1.549539647667792, 'param_17': -1.331839407122311, 'param_18': -0.039142748353186985, 'param_19': -1.7013318960759518, 'param_20': 0.4006888920067415, 'param_21': -1.8369707275607308, 'param_22': 0.9217539215602537, 'param_23': 0.8586870962120892, 'param_24': 0.36019102109931955, 'param_25': 1.8293834075580366, 'param_26': -0.23245098437709943, 'param_27': -1.5845914525191356, 'param_28': -1.1975535360410903, 'param_29': 1.7603990149535647, 'param_30': 1.8107814578289583, 'param_31': 1.059210333412714, 'param_32': 1.5229041172556341, 'param_33': 0.9696412324137951, 'param_34': -1.9645356166015424, 'param_35': 0.37323103605448527, 'param_36': -0.3587028018401539, 'param_37': 1.6159761132063761, 'param_38': 1.7029307268004246, 'param_39': 1.5474237651248033, 'param_40': -0.5976083246696526, 'param_41': 1.5516901416412283, 'param_42': 0.014381149815268834, 'param_43': -1.358401614807268, 'param_44': -1.0579113002214093, 'param_45': 1.4854895415288936, 'param_46': 0.9424905874574927, 'param_47': 0.8310950342729089, 'param_48': -0.6908501072844047, 'param_49': 0.3082079495446792, 'param_50': 1.637052436172938, 'param_51': 1.5327170111441637, 'param_52': 0.7453623550472437, 'param_53': -0.07829423260933943, 'param_54': 1.9883126451079662, 'param_55': -1.084297065520929, 'param_56': -0.006330222152779896, 'param_57': -0.6259241432493576, 'param_58': -0.8881333963176008, 'param_59': 0.20964905174547122, 'param_60': 0.363550363241969, 'param_61': 1.4562409459699932, 'param_62': 1.8846336892697257, 'param_63': -0.5652894458056386, 'param_64': -1.4931580589587927, 'param_65': -1.0705885972918012, 'param_66': 0.08857102193859534, 'param_67': -0.8682699797478204, 'param_68': -1.0258760675037228, 'param_69': -1.344419178924682, 'param_70': 1.7855783667702796, 'param_71': 0.2504864297528666, 'param_72': 0.02119054068481363, 'param_73': 0.43420580865768343, 'param_74': -0.43001529673250083, 'param_75': 1.3938974555233097, 'param_76': -1.2418551024846098, 'param_77': 0.7498866739113814, 'param_78': -1.4067745278575123, 'param_79': 0.556892425381124, 'param_80': 0.994940400936176, 'param_81': -0.38219616741344264, 'param_82': -1.3763313126355459, 'param_83': -1.7284883366973345, 'param_84': 1.989258449982641, 'param_85': -1.373175119427252, 'param_86': 0.9646596820358795, 'param_87': 0.26305585245107466, 'param_88': 1.0316482234025477, 'param_89': 0.7855343114460225, 'param_90': 0.23906072839363368, 'param_91': 0.2873437138834163, 'param_92': -0.35291079219854016, 'param_93': -1.129645810000952, 'param_94': 1.51487340479183, 'param_95': 0.3251481158899199, 'param_96': 0.0047256782670688224, 'param_97': -0.8339686069402554, 'param_98': -1.933050900158252, 'param_99': 1.3100599777387303, 'param_100': -0.6435797094089151, 'param_101': -0.5147442358279788, 'param_102': -0.031322247960667404, 'param_103': -1.3053201362600464, 'param_104': 0.9358934259306806, 'param_105': 0.2188099717899421, 'param_106': 1.542226199750222, 'param_107': 0.7214421253216412, 'param_108': -1.307585421788823, 'param_109': -0.36714041068984793, 'param_110': 0.6289688021143012, 'param_111': 0.7083421879039604, 'param_112': -1.1199431962922186, 'param_113': 1.6169267510952294, 'param_114': -0.9221248773004622, 'param_115': 1.694653409848697, 'param_116': -1.8205058700234904, 'param_117': -0.4685399264728285, 'param_118': -1.3452328892391598, 'param_119': -0.9387755353282237, 'param_120': -1.9340676231689877, 'param_121': -1.1642937053989337, 'param_122': -0.6925212307852631, 'param_123': -0.3441769547069278, 'param_124': 0.6855184292760628, 'param_125': -0.8134320987620152, 'param_126': -0.3608610870369722, 'param_127': 0.6597796442697614, 'param_128': -1.2711450002409115, 'param_129': 1.8857195738946384, 'param_130': 1.8921028384701923, 'param_131': -0.7474532215348453, 'param_132': 1.0634672132288334, 'param_133': 1.7549738753930688, 'param_134': -1.0948674515547139, 'param_135': -0.6424823119634451, 'param_136': -0.5943715503255604, 'param_137': -0.5814830786074796, 'param_138': -1.1094181527522258, 'param_139': -0.9353509282698997, 'param_140': 1.2569592769925433, 'param_141': 1.4699792958397375, 'param_142': 0.11698171634601495, 'param_143': 0.7144782882332108, 'param_144': 1.4504699639922984, 'param_145': -1.7592125644893861, 'param_146': 1.4884214451906534, 'param_147': 1.1984312314610004, 'param_148': 1.398340089398323, 'param_149': -1.4113399986398143, 'param_150': -0.16795487938921294, 'param_151': 1.02289006382623, 'param_152': 1.3353938532866647, 'param_153': 0.5830532853200787, 'param_154': -1.81635355880571, 'param_155': 1.789808106826809, 'param_156': 1.8542112374521338, 'param_157': 1.76095753763031, 'param_158': 0.7433224385703592, 'param_159': 1.7207999634837958, 'param_160': -0.8689696102892528, 'param_161': -0.8457590163255757, 'param_162': -1.6404164123620553, 'param_163': -0.9820621527128766, 'param_164': 0.2397832662409436, 'param_165': 1.1481160113864934, 'param_166': 0.1555630581999452, 'param_167': -1.8924117184156573, 'param_168': 1.6061127140744125, 'param_169': -0.8136263914182855, 'param_170': -0.27403703120636225, 'param_171': -1.3437304441159914, 'param_172': -0.844155552475085, 'param_173': 0.83474224779826, 'param_174': 1.2483147969997628, 'param_175': 0.45317877580785915, 'param_176': -1.65321408691663, 'param_177': 0.17227211290442845, 'param_178': 0.8438345705728887, 'param_179': 0.9517687890160302, 'param_180': 1.1154499524646515, 'param_181': 0.8323330490925747, 'param_182': -1.6934711095168962, 'param_183': -1.7790207040556716, 'param_184': -1.4911274425529828, 'param_185': 0.8296057572539022, 'param_186': -0.9589423144887346, 'param_187': -0.8684124311593457, 'param_188': 0.6861910083434606, 'param_189': -0.9600410364024592, 'param_190': 1.2867831060161081, 'param_191': -0.8660240053841721, 'param_192': -1.5074610312422183, 'param_193': -1.7453181436283938, 'param_194': -1.5831742385203205, 'param_195': 0.16539089753672043, 'param_196': 0.6584911874108115, 'param_197': -1.7200682883660696, 'param_198': -1.3725500484701056, 'param_199': 0.2575846999407272, 'param_200': -0.4373034554169082, 'param_201': 0.38991707006193677, 'param_202': 0.3436058388639305, 'param_203': -1.708060937156394, 'param_204': -0.061827074416365146, 'param_205': 1.1201920981888813, 'param_206': -1.3699378848086154, 'param_207': 0.5684180310771927, 'param_208': 1.7944456362870134, 'param_209': -0.6470068337451385, 'param_210': 0.36944792734304066, 'param_211': 0.6985349659642477, 'param_212': 0.20980670205832164, 'param_213': -1.4845417544839794, 'param_214': -1.16384760231186, 'param_215': -1.148782208173364, 'param_216': -1.7570535731233692, 'param_217': -0.060101946834864695, 'param_218': 0.8802003179021423, 'param_219': -1.6144265298972695, 'param_220': 1.8847371367032428, 'param_221': -0.791704320428539, 'param_222': -1.5987617577087647, 'param_223': -1.6910167411647086, 'param_224': 0.6078605767361842, 'param_225': -0.059049240643633816, 'param_226': -1.403018367851264, 'param_227': -1.8111183701917875, 'param_228': -0.876783958667489, 'param_229': 0.993520738044595, 'param_230': 0.7763575604690462, 'param_231': 1.8882949027333007, 'param_232': 0.48542371526712325, 'param_233': 1.3289394797717442, 'param_234': -0.12352356822833421, 'param_235': 1.2932679767586759, 'param_236': -1.680626390384024, 'param_237': 0.9765455973555097, 'param_238': -0.1763394533515248, 'param_239': 0.24325238267767713, 'param_240': -0.5972038700134159, 'param_241': -0.0077146995115020545, 'param_242': 0.38829405421441354, 'param_243': 0.9415806058125651, 'param_244': 0.1967736633999606, 'param_245': 0.3654321952136059, 'param_246': 1.729177783565679, 'param_247': -1.7334009871028404, 'param_248': 0.3559096431672595, 'param_249': -0.35725839990234975, 'param_250': -0.9850827398003887, 'param_251': -0.01959406747919168, 'param_252': -0.34869142175406864, 'param_253': 1.7251776326014885, 'param_254': -0.3975577684479874, 'param_255': -0.5147471353591522, 'param_256': -0.07960639639379297, 'param_257': -0.4269206649878883, 'param_258': 1.8445415433078143, 'param_259': 1.6205930077715456, 'param_260': -1.5774077405680882, 'param_261': -0.7639232459626131, 'param_262': 0.360164954345056, 'param_263': -1.4000720570219434, 'param_264': -0.9163569995332734, 'param_265': 0.3424106173600081, 'param_266': 0.6521442155400652, 'param_267': 0.20926711576928136, 'param_268': -0.19681943695570814, 'param_269': -1.7051319566979841, 'param_270': 1.6405809174745305, 'param_271': -1.4960807982987876, 'param_272': -0.9739309155667204, 'param_273': -0.5127809611504848, 'param_274': -0.11264085385557454, 'param_275': 0.038969541800650376, 'param_276': 0.264804078478714, 'param_277': 1.817652682620678, 'param_278': 0.9307360088129428, 'param_279': -0.8021178208098672, 'param_280': 1.023191333811054, 'param_281': 0.18696771585375238, 'param_282': 1.2535920117656008, 'param_283': 0.6522708668011719, 'param_284': -1.1046488631599027, 'param_285': -0.8230884434242314, 'param_286': -0.6182763012696055, 'param_287': 1.6591953903267953, 'param_288': 1.5684610883890202, 'param_289': -0.3096051517725873, 'param_290': 0.1217449950534415, 'param_291': -1.4398652299407564, 'param_292': 1.813534115688372, 'param_293': 0.5164387806068325, 'param_294': 0.8352320485747224, 'param_295': 0.8285006292539756, 'param_296': -1.966459091626862, 'param_297': -1.7175066936870231, 'param_298': 0.38984161038778, 'param_299': 1.6723854766444122, 'param_300': 1.0993081417805164, 'param_301': -1.8974845391220168, 'param_302': -1.660036721721815, 'param_303': -0.8182609078186402, 'param_304': -1.2671654176575697, 'param_305': 0.896187703625356, 'param_306': 0.5780662162989554, 'param_307': 0.5662359560605155, 'param_308': 0.5068759549628981, 'param_309': -1.5258748591882352, 'param_310': -1.6451182622277067, 'param_311': 0.817278802175784, 'param_312': 1.1759638772971752, 'param_313': 0.16827688562302479, 'param_314': 0.44355267946015875, 'param_315': -0.08219174592181311, 'param_316': 0.39047119626280136, 'param_317': -0.47047040542834884, 'param_318': -1.3232571698647444, 'param_319': 1.877620173624479, 'param_320': -1.0739780229546745, 'param_321': -1.909350133455591, 'param_322': -1.4426473006891865, 'param_323': 0.7071912872242874, 'param_324': 0.453631359848528, 'param_325': -0.1958044676747006, 'param_326': 1.2990570030505744, 'param_327': -0.5615924249225119, 'param_328': 0.4449094614638587, 'param_329': 0.49431320065159623, 'param_330': 0.9005926270288409, 'param_331': 1.4944424045639364, 'param_332': 1.704624431722391, 'param_333': 1.9671264563233306, 'param_334': 0.837608967363173, 'param_335': 0.20275864460753512, 'param_336': -0.7865757931538546, 'param_337': -1.4143920074632628, 'param_338': 0.9459272872976556, 'param_339': -0.9864467957856946, 'param_340': 1.8624455323318174, 'param_341': 1.3849562507427682, 'param_342': -0.06697526130799014, 'param_343': 1.6243183943071244, 'param_344': 0.06373806676909721, 'param_345': 1.3053549775330047, 'param_346': 0.3169748723204755, 'param_347': 0.806771668230899, 'param_348': 1.5006554743573477, 'param_349': -0.258208607474816, 'param_350': 0.07259206305694077, 'param_351': 0.382731282373332, 'param_352': 1.2449644390908108, 'param_353': 1.6155996211980037, 'param_354': 0.5963317995258524, 'param_355': 0.42642526888865007, 'param_356': 0.6224576713067358, 'param_357': 0.2645621005570278, 'param_358': 0.6374166535526751, 'param_359': 1.0107035967868998, 'param_360': -0.8358805034221111, 'param_361': 1.6114074466253547, 'param_362': 1.5511289724703508, 'param_363': -1.449826752115861, 'param_364': -0.3732818875031274, 'param_365': -1.2894512340275202, 'param_366': -1.7455004090869681, 'param_367': 0.23234787784088606, 'param_368': 0.5906028581666796, 'param_369': 1.0862923158928068, 'param_370': 1.3718021745238769, 'param_371': -0.22546253132327232, 'param_372': -0.4016946122052336, 'param_373': -0.19757347300311157, 'param_374': -1.593446038220386, 'param_375': -0.7673265503973754, 'param_376': 0.9202084147665222, 'param_377': 1.1767453451921752, 'param_378': -1.130397931905636, 'param_379': -0.4654715006719794, 'param_380': -1.7736217131602352, 'param_381': -0.7238653401114545, 'param_382': 0.3024797575709317, 'param_383': 1.6502392291378762, 'param_384': 1.0250292355269321, 'param_385': -1.5413539986240594, 'param_386': 1.20033831069889, 'param_387': -1.9079896067542563, 'param_388': -0.6677674928769242, 'param_389': 0.42687152724546573, 'param_390': 1.4235259601239671, 'param_391': -1.4772175618836827, 'param_392': 1.445505466953445, 'param_393': -0.035272865363623396, 'param_394': 1.177875830619818, 'param_395': 1.5552688053365906, 'param_396': -1.9293352476274213, 'param_397': -0.411704484048097, 'param_398': 0.1420196286365938, 'param_399': 0.8099489862418032, 'param_400': 1.6563350785982252, 'param_401': -0.3371151981117655, 'param_402': -0.49973669305279556, 'param_403': 1.0826175411304915, 'param_404': -1.5355731142318816, 'param_405': -1.9573814242364227, 'param_406': -0.7485171520467158, 'param_407': 1.2024360494841804, 'param_408': -0.8582848329506723, 'param_409': -0.5943431613817349, 'param_410': -0.7816348072459807, 'param_411': 0.24750693264932933, 'param_412': 1.7941062491609796, 'param_413': 1.7383278819838206, 'param_414': -0.6939398724397732, 'param_415': 0.4556302712623794, 'param_416': 0.7951346522331235, 'param_417': -0.230163927613662, 'param_418': -0.029714333938932747, 'param_419': -0.055222918254213216, 'param_420': 1.3939768913773438, 'param_421': 1.8382724107495299, 'param_422': 1.1019781354092641, 'param_423': 0.9111819702754467, 'param_424': -0.47898558947550374, 'param_425': 0.5759203503485244, 'param_426': -0.19637543683555458, 'param_427': -1.58680749251493, 'param_428': -0.5121982064372768, 'param_429': 0.5242318786214359, 'param_430': -0.5763980392118078, 'param_431': -0.41311007607115124, 'param_432': -1.4741416009672936, 'param_433': -1.5490203749435474, 'param_434': -0.6166296837686427, 'param_435': 0.5658871487810311, 'param_436': 0.2317287260656613, 'param_437': 0.005376266489951487, 'param_438': 1.9515742245871435, 'param_439': 0.2654073433657307, 'param_440': -1.522082276213803, 'param_441': -1.0145583965038045, 'param_442': 0.36327161583518297, 'param_443': 1.3871582229185169, 'param_444': -0.3179509743155169, 'param_445': -0.6322953330460126, 'param_446': -0.442606306559552, 'param_447': -1.939092391373447, 'param_448': -0.6481618702219833, 'param_449': -0.33028644459120304, 'param_450': -0.847023484815923, 'param_451': -1.6565526837218774, 'param_452': -0.1779341440467861, 'param_453': 1.3299035649395226, 'param_454': 1.4085034113849146, 'param_455': 1.0624829742743591, 'param_456': -1.7645294587393483, 'param_457': 1.3843816782472387, 'param_458': -1.5505634315577295, 'param_459': 0.032453846295924293, 'param_460': -1.9841969217572637, 'param_461': -0.6793524646201061, 'param_462': -1.453318398271549, 'param_463': 0.5652876452245699, 'param_464': -1.9821352324458088, 'param_465': -0.3590754103108069, 'param_466': -1.8325136786635827, 'param_467': -0.5649717391397138, 'param_468': 1.8149494689315406, 'param_469': 1.890080905066776, 'param_470': -0.25598776772665577, 'param_471': 1.475406054438948, 'param_472': 1.5314145628347582, 'param_473': 0.6666900662868271, 'param_474': -0.1888671458957707, 'param_475': -0.6390512072507777, 'param_476': -0.6455693738794435, 'param_477': 1.1612077448733653, 'param_478': -1.8142188497968843, 'param_479': -0.11502426360701623, 'param_480': -1.664298082032237, 'param_481': 0.8036238976644832, 'param_482': -1.9932166538310532, 'param_483': 1.6602441118193503, 'param_484': -1.2315269057218203, 'param_485': 1.4787777970476061, 'param_486': -1.0618360697697677, 'param_487': 1.039167311235723, 'param_488': -1.2142017062819481, 'param_489': 1.8071690300290584, 'param_490': -1.6332884297431165, 'param_491': 0.457595436435998, 'param_492': -1.9645999023028744, 'param_493': -1.7618743769369463, 'param_494': 1.1960522207314335, 'param_495': 0.1104991111826914, 'param_496': -1.738897552457321, 'param_497': 0.05215363027058162, 'param_498': -0.8052921366059551, 'param_499': 0.37131109633923565, 'param_500': 0.16433466195492663, 'param_501': 0.873165959244607, 'param_502': 1.1936134701074979, 'param_503': 1.8512255556736297, 'param_504': 1.2863224770896857, 'param_505': 1.8454325327829593, 'param_506': 1.996121771082135, 'param_507': -1.2010213789212396, 'param_508': -1.4948174280460274, 'param_509': -1.8857919537216081, 'param_510': -0.5834193239345074, 'param_511': 0.7217934165179116, 'param_512': -0.947573100908421, 'param_513': -0.6299663123719612, 'param_514': 0.6307080864877896, 'param_515': 1.8753484620932088, 'param_516': 1.1425852298751638, 'param_517': -0.5147487970908822, 'param_518': 0.25155084440132214, 'param_519': -1.6182962509963947, 'param_520': -1.1996725763440494, 'param_521': 1.3688495181358116, 'param_522': 0.3349731404566634, 'param_523': 0.45570106054942094, 'param_524': 1.3810098377382256, 'param_525': 1.6099996888585832, 'param_526': -0.3334559789119669, 'param_527': -1.1276880035623864, 'param_528': 0.4864162601169735, 'param_529': -1.2747734104125352, 'param_530': -0.5871337727869963, 'param_531': -1.4123014403071612, 'param_532': -1.6831341243365818, 'param_533': -0.8675236892492588, 'param_534': -0.43912531807298505, 'param_535': -1.191829570991517, 'param_536': 0.41259460637931644, 'param_537': 1.8220141251828474, 'param_538': 0.2017232721345681, 'param_539': 0.807929430096396, 'param_540': -1.595823462363537, 'param_541': -1.4099678062328755, 'param_542': -0.41110298634750286, 'param_543': 1.9692258459738428, 'param_544': -1.2587062707458525, 'param_545': 0.37984596211649535, 'param_546': -0.5287600604356166, 'param_547': -1.9991168558339512, 'param_548': 0.8544018268977571, 'param_549': -1.7041276297392463, 'param_550': 1.0616040187192621, 'param_551': 0.46426565274155784, 'param_552': 0.7071846151347234, 'param_553': -0.4157191160135927, 'param_554': 0.3720447527388626, 'param_555': -1.1647396299364527, 'param_556': -0.1977059975103148, 'param_557': -1.0539042906997436, 'param_558': -1.7778618816524605, 'param_559': -1.3780773852585355, 'param_560': -1.326254904914482, 'param_561': 0.6606507437614555, 'param_562': -1.084283245617649, 'param_563': 1.8076655730942672, 'param_564': -0.6550953104257564, 'param_565': 1.2835627441539592, 'param_566': 0.1998261179149763, 'param_567': -0.5584462732207451, 'param_568': -0.5472608842526792, 'param_569': -1.9375970835750662, 'param_570': -1.2236473709383797, 'param_571': -0.3933220676419329, 'param_572': -1.0096437196264603, 'param_573': -1.8427831994656994, 'param_574': 0.37945768735452345, 'param_575': -0.25533901620094346, 'param_576': -1.0433267020458685, 'param_577': -0.3016710810049248, 'param_578': 1.120023181392614, 'param_579': 0.06914830162898822, 'param_580': -1.2336235321026372, 'param_581': -1.6345890108728431, 'param_582': 0.7592828877240358, 'param_583': 1.7282106491889602, 'param_584': 1.8106959287283422, 'param_585': -0.9101057225609708, 'param_586': -0.275160990549042, 'param_587': 1.76615871434834, 'param_588': 0.6766865491886409, 'param_589': -1.8887118743837732, 'param_590': 1.878491698539471, 'param_591': 1.0027006511661272, 'param_592': 1.8291353502092553, 'param_593': 1.8678667201502885, 'param_594': 0.35835943377156987, 'param_595': 1.9945752241339605, 'param_596': 1.759698685445941, 'param_597': -0.7655003333561492, 'param_598': -0.7055242918458147, 'param_599': -1.5273581644429943, 'param_600': 0.6116700704355624, 'param_601': -1.7500308331483163, 'param_602': -1.1256821206642322, 'param_603': -1.7313160736972608, 'param_604': -0.3647709185010335, 'param_605': -1.2457362663243448, 'param_606': 0.7712788220962694, 'param_607': -0.046572706672669106, 'param_608': 1.1351660316125716, 'param_609': -0.35626396693547946, 'param_610': 0.42309081087935585, 'param_611': -0.014850934207109034, 'param_612': -1.9233307915776154, 'param_613': -1.5679594860350687, 'param_614': -1.8504140052625329, 'param_615': -1.3536684008687807, 'param_616': 0.2788556373496869, 'param_617': -0.5952800906728424, 'param_618': -0.4143062812554601, 'param_619': -0.9254056738643004, 'param_620': -0.20566329420135965, 'param_621': 1.2305120973464292, 'param_622': 0.4542656321737599, 'param_623': 1.9032260137311319, 'param_624': -1.3001704637428575, 'param_625': 1.7395605341062543, 'param_626': -0.2475186651396184, 'param_627': -1.9709032410641512, 'param_628': -0.7794277527716016, 'param_629': -0.7975099270622374, 'param_630': -0.8936550973997974, 'param_631': -1.4991112848801746, 'param_632': 0.6452494125821095, 'param_633': -1.079600136348545, 'param_634': 1.9255418306008836, 'param_635': 0.19557375723619153, 'param_636': -0.47088580169297023, 'param_637': -0.46084563957584823, 'param_638': -1.5364853912310124, 'param_639': 0.38088864954935087, 'param_640': -0.4623933404830085, 'param_641': -1.7024683503061633, 'param_642': 1.0155511219656934, 'param_643': 0.47964916888397946, 'param_644': 0.3733985496784129, 'param_645': 0.10100473107027197, 'param_646': 1.6708049848382114, 'param_647': -0.13081126962497747, 'param_648': -0.15857699876130438, 'param_649': -0.2430657670112506, 'param_650': -0.9724034082973909, 'param_651': 1.2206527955603144, 'param_652': 1.5923243643269949, 'param_653': 0.3018852428668577, 'param_654': -1.4189936749582954, 'param_655': 1.4925114815797071, 'param_656': -0.3816514339556041, 'param_657': -0.06652823303222011, 'param_658': -1.4138125381706055, 'param_659': -1.7443129041285492, 'param_660': 1.592847986857592, 'param_661': -1.3075640775251687, 'param_662': -1.952731739759964, 'param_663': 0.41792963011996465, 'param_664': -0.6536951682731678, 'param_665': -1.5581910668920638, 'param_666': 0.8901421335504307, 'param_667': -1.654546458607407, 'param_668': 1.4197550602111182, 'param_669': -0.30733536117067484, 'param_670': -0.1196181402939609, 'param_671': -0.032584608183995556, 'param_672': -1.0742749750746117, 'param_673': -0.39269572158837684, 'param_674': -1.5110344394553694, 'param_675': -1.6916946183164483, 'param_676': -0.6205425446318413, 'param_677': -1.7568121972217168, 'param_678': 1.7197326392899521, 'param_679': -0.24359592664230467, 'param_680': -1.664812297855367, 'param_681': -1.1816731769530144, 'param_682': -1.745093203667615, 'param_683': 0.6402048906787838, 'param_684': 0.28183913458298493, 'param_685': 0.37373516264018125, 'param_686': -0.5382786492032268, 'param_687': -1.6494041981545657, 'param_688': -1.425864217430087, 'param_689': -1.982707581374124, 'param_690': 1.9528586682562756, 'param_691': 1.577166105594685, 'param_692': -0.36952495623157144, 'param_693': -1.9557666833705718, 'param_694': 1.258047744803112, 'param_695': 1.0394877143685566, 'param_696': 0.9959905788239771, 'param_697': -0.35718916304932335, 'param_698': 1.9383321900680786, 'param_699': 0.005531634156307863, 'param_700': -1.1874143693036934, 'param_701': 1.129666424539503, 'param_702': 0.38778463995499246, 'param_703': 0.8796103492388272, 'param_704': 0.31571829412560426, 'param_705': -0.12316663050942722, 'param_706': -1.1743530908002113, 'param_707': 1.8250629323126986, 'param_708': 1.8137775262035372, 'param_709': 1.4298071478806778, 'param_710': 1.4988099238547767, 'param_711': -1.5353051431507003, 'param_712': 1.2585358965514026, 'param_713': 0.8240939889380847, 'param_714': -0.5185268154047149, 'param_715': -1.402806995253961, 'param_716': -0.08129009603109116, 'param_717': 0.9525847542436816, 'param_718': 1.3430425273613302, 'param_719': -1.3956055722093814, 'param_720': 1.0922728001492934, 'param_721': -0.7096824826558192, 'param_722': 1.9377277891520293, 'param_723': -0.5108123124286892, 'param_724': 0.12726630431779018, 'param_725': -1.0816977005682005, 'param_726': 1.9149929376186203, 'param_727': -0.594703047301989, 'param_728': 0.9763230003286112, 'param_729': -0.4561021164760506, 'param_730': 0.4687147568692769, 'param_731': -1.0317498651360109, 'param_732': -1.6576374054915326, 'param_733': 1.447245975213221, 'param_734': -0.05652503804130937, 'param_735': 0.6443016452957258, 'param_736': 0.8971545446391516, 'param_737': 0.6354376769531718, 'param_738': -0.7075817745616901, 'param_739': -1.5205194337933312, 'param_740': 1.856447508253694, 'param_741': -1.7429482033523787, 'param_742': -1.965361348240965, 'param_743': 1.0056773743518455, 'param_744': 0.6541411062921947, 'param_745': -1.1187495364697688, 'param_746': -0.6539122177309946, 'param_747': -0.7069255028113206, 'param_748': 0.03447114295875098, 'param_749': 0.8133763990341629, 'param_750': -1.2813876775408493, 'param_751': 1.011939925637074, 'param_752': 1.634848388840501, 'param_753': -0.9994553782381494, 'param_754': 0.7691621700318607, 'param_755': 0.6226117976032128, 'param_756': 1.9900492339023108, 'param_757': 1.7918660720998165, 'param_758': -0.061848351659370415, 'param_759': 0.041215604245874005, 'param_760': 1.7794033364391488, 'param_761': -0.042748119083615865, 'param_762': -1.7447498154881282, 'param_763': -0.7744732443926137, 'param_764': -0.606655477493677, 'param_765': 1.1162500275207248, 'param_766': 1.1712684752432976, 'param_767': 0.5475743816278809, 'param_768': -1.8150777512287486, 'param_769': -1.5439943323804326, 'param_770': 1.3849715883454392, 'param_771': -0.9623680961620891, 'param_772': -1.6288320914775918, 'param_773': -0.49935252976665057, 'param_774': 1.3959860313240378, 'param_775': -1.0082770945768411, 'param_776': -0.9044062743013876, 'param_777': 1.6727680164500236, 'param_778': 0.6348752931934278, 'param_779': -1.9935972809784541, 'param_780': -0.2530081334361487, 'param_781': -0.059993888705936804, 'param_782': -1.9386284022579625, 'param_783': -0.3610241968373664, 'param_784': -1.1994323006135077, 'param_785': -0.5626954152600994, 'param_786': 1.2203085940844418, 'param_787': 1.8600143677548133, 'param_788': 1.0873368225278686, 'param_789': 1.5083785969881207, 'param_790': -1.085779272508565, 'param_791': -0.2009372885140568, 'param_792': -1.5552422166841118, 'param_793': -1.6770472343348275, 'param_794': 1.4815282829953755, 'param_795': -1.539967523420537, 'param_796': 1.068863938990138, 'param_797': 0.986219282644182, 'param_798': 0.6201791591338441, 'param_799': -1.78242347744514, 'param_800': -1.3573484267782385, 'param_801': -0.5300756004214877, 'param_802': 0.0667950370654129, 'param_803': 1.3575368674826924, 'param_804': -1.231290166636862, 'param_805': 0.8094443842869632, 'param_806': 1.3211555095144227, 'param_807': 0.8354623140623114, 'param_808': 1.5016791701286012, 'param_809': -1.6447898056102095, 'param_810': -1.514187530681684, 'param_811': -1.5752738202494792, 'param_812': -0.38069769132036013, 'param_813': 1.7552951090745506, 'param_814': -0.6658747750098328, 'param_815': -1.8233178172437952, 'param_816': 1.7770759197702892, 'param_817': -1.499891596874137, 'param_818': -0.3126748952855718, 'param_819': -0.4413422053827949, 'param_820': 1.8762486197271384, 'param_821': -0.017158131659009257, 'param_822': -0.6031536312026042, 'param_823': 1.880199042125625, 'param_824': -0.06943913476186747, 'param_825': 1.6112311390235377, 'param_826': 1.8477291683272314, 'param_827': 1.8626933389972926, 'param_828': 1.7528139286538487, 'param_829': 0.04331087922516019, 'param_830': 0.1654420934257521, 'param_831': 0.16601133332956408, 'param_832': -1.0517064728687577, 'param_833': 0.2590777929350261, 'param_834': -1.565275949726571, 'param_835': 1.9043026329867585, 'param_836': 1.6920636423058086, 'param_837': 0.8004361443696788, 'param_838': -0.5163175132982358, 'param_839': -0.5804495116697845, 'param_840': -1.676781700913085, 'param_841': -0.8433032565659415, 'param_842': 0.5861987990732991, 'param_843': 1.50839007227147, 'param_844': 1.7790199916027132, 'param_845': -0.8098151653715817, 'param_846': 0.19457002254288636, 'param_847': 0.4335681350032008, 'param_848': -1.8166215726973536, 'param_849': -0.07170383155296012, 'param_850': -0.17204298326985734, 'param_851': -1.1764254666897331, 'param_852': 1.5739209131620049, 'param_853': 1.0303762312482356, 'param_854': 1.5470538801461804, 'param_855': 1.0043596471809475, 'param_856': 1.1462693615103698, 'param_857': -0.135124678124654, 'param_858': 1.9158386174993356, 'param_859': -0.9377681442210717, 'param_860': -1.121399336784755, 'param_861': -1.6147394314425298, 'param_862': 1.9696199213467587, 'param_863': -0.9752284032073777, 'param_864': 1.908557998801896, 'param_865': -0.084988366960284, 'param_866': 1.2663784467360624}. Best is trial 0 with value: 73.16343157057685.\n",
      "[W 2023-06-19 14:24:44,492] Trial 1 failed with parameters: {'param_0': 0.6404577820919339, 'param_1': -0.04248212385109773, 'param_2': -0.15312595530914042, 'param_3': -0.06464494773045737, 'param_4': -0.5520291784427798, 'param_5': -0.8281281089269388, 'param_6': 0.3009132512333763, 'param_7': -1.2700468650515078, 'param_8': 0.6923706058611656, 'param_9': 0.8950096282217492, 'param_10': 0.2669595074289086, 'param_11': 0.7961506782546381, 'param_12': 0.1905106381013324, 'param_13': -0.5661292543295464, 'param_14': 0.36709036724639965, 'param_15': -1.0079769304136954, 'param_16': -1.492207483634369, 'param_17': -0.8569904505211774, 'param_18': 0.3951337915843105, 'param_19': -1.3222037139849885, 'param_20': 0.04752614205246397, 'param_21': 0.006916384069633352, 'param_22': 0.546978974122367, 'param_23': -0.051447241652959, 'param_24': 0.6970211041817849, 'param_25': -0.12512097892603902, 'param_26': 0.7366007241516255, 'param_27': 0.5726686958672662, 'param_28': 0.6349785048728984, 'param_29': -0.31067162338890286, 'param_30': 0.2212378120357088, 'param_31': 0.9646868615409061, 'param_32': -0.15462651137088912, 'param_33': 0.4627588556798039, 'param_34': 0.10113861662294399, 'param_35': 0.007172314258396373, 'param_36': -0.0995555437080553, 'param_37': -0.07174049344141697, 'param_38': 0.53205801959195, 'param_39': -0.828667571289502, 'param_40': -0.060319552269934906, 'param_41': 0.6019624996669042, 'param_42': 1.0220110861098006, 'param_43': -0.8915880046352203, 'param_44': 0.23585945636189987, 'param_45': -0.1557867136394726, 'param_46': 0.12929153877359312, 'param_47': 0.07205206210644244, 'param_48': 0.8729374235475778, 'param_49': 0.6652520814888412, 'param_50': -0.37954226525507573, 'param_51': 0.30068961136303995, 'param_52': -0.3042281397682145, 'param_53': 0.16449541355747677, 'param_54': 0.44819401766091005, 'param_55': -1.3904294728718312, 'param_56': 1.3542277112716854, 'param_57': 0.24499772381368512, 'param_58': -0.8565593608406434, 'param_59': 0.12282173171984523, 'param_60': -0.6430207106706345, 'param_61': -0.6925233913839748, 'param_62': -0.21593516859265516, 'param_63': 0.3587061148949253, 'param_64': 0.03385050159838121, 'param_65': 0.050588609677941765, 'param_66': -0.3727716511307919, 'param_67': 0.8308617024048979, 'param_68': -0.9686315259117779, 'param_69': -0.019044446295295003, 'param_70': -0.3210138214829108, 'param_71': -1.167898506377616, 'param_72': -0.648370299397129, 'param_73': 0.2471709844829144, 'param_74': 0.019474803954806053, 'param_75': -0.3924531524034611, 'param_76': 0.12317603724320847, 'param_77': -0.18443768024236662, 'param_78': -0.2568550731046795, 'param_79': -0.8002176651106492, 'param_80': 0.02296642390729886, 'param_81': 0.8580608491722614, 'param_82': -0.057386774414173614, 'param_83': -0.5280828643042486, 'param_84': 0.05037137194837982, 'param_85': -0.24143736651396797, 'param_86': 0.2455921231178988, 'param_87': -0.12330203343561941, 'param_88': 0.26412266093252645, 'param_89': -0.10357936472435059, 'param_90': 0.6102644682011285, 'param_91': 0.13617368139640185, 'param_92': 1.2195210213245051, 'param_93': 1.0794436215865884, 'param_94': 0.9440597437175642, 'param_95': 0.21751210319783043, 'param_96': 0.19589200268892437, 'param_97': -0.11250074932692167, 'param_98': -1.1164626420871349, 'param_99': 0.6917967703932697, 'param_100': -1.0296050938875496, 'param_101': 0.06570227109561833, 'param_102': -1.798477040701437, 'param_103': -1.1660450878672384, 'param_104': -0.5757129503269784, 'param_105': -0.4713731562896215, 'param_106': -0.15514700368927237, 'param_107': -0.22466312365387786, 'param_108': 0.3524304313556019, 'param_109': 0.3684583156881587, 'param_110': 0.40906361514626166, 'param_111': -1.9497420408079185, 'param_112': -0.7263768767334704, 'param_113': -0.611268417589002, 'param_114': 0.11925086363898796, 'param_115': -0.3645946108820557, 'param_116': 0.5993915586422931, 'param_117': 0.5793581894875812, 'param_118': 0.4915132062037899, 'param_119': -0.7185686913308478, 'param_120': 0.9816394431106419, 'param_121': 0.821596777488752, 'param_122': 0.5845018298247648, 'param_123': 0.7383864717229027, 'param_124': 1.4826657067420772, 'param_125': -0.03726917413266917, 'param_126': 0.8096633645574718, 'param_127': -0.8849543188886708, 'param_128': -0.8784235677979382, 'param_129': -0.9468382459367661, 'param_130': -0.1691765894823729, 'param_131': 0.3764240753127601, 'param_132': 0.6551960042765579, 'param_133': 0.7730786015226476, 'param_134': 0.8778038600862326, 'param_135': 0.1009894053793623, 'param_136': -1.1815445126412691, 'param_137': -0.893338523167448, 'param_138': -0.10944733722088817, 'param_139': -0.010640560062437299, 'param_140': 0.3607647633443771, 'param_141': 0.5902234531592709, 'param_142': -0.12091145724541108, 'param_143': 1.024427802446087, 'param_144': -0.12249557760122465, 'param_145': 0.8441596115821883, 'param_146': 0.8210836895358109, 'param_147': 0.9980743065265218, 'param_148': 0.3348967569635666, 'param_149': -0.016499211368212308, 'param_150': -0.45863868189291934, 'param_151': 0.20406582424516673, 'param_152': 0.48144135292226453, 'param_153': 0.534135944276878, 'param_154': -0.5797297026986052, 'param_155': -1.2564718749525043, 'param_156': -0.1360173262148594, 'param_157': 0.4298347623114096, 'param_158': 0.3870000957064459, 'param_159': -0.6051316617661893, 'param_160': -0.5248418324205861, 'param_161': -1.7110405937078799, 'param_162': 0.8553403865273879, 'param_163': -0.7468063491369556, 'param_164': -0.7069246817388, 'param_165': -0.12363995879586498, 'param_166': -0.4916586692252234, 'param_167': -0.4019045340597005, 'param_168': -0.47547445885026307, 'param_169': 0.8494312720629154, 'param_170': 0.7502808647354824, 'param_171': -1.4851435894324618, 'param_172': 0.2752418780314172, 'param_173': -0.7800261872518561, 'param_174': -0.4636475127895976, 'param_175': -0.6095567225396072, 'param_176': -0.6084828050833029, 'param_177': -0.060954843926885216, 'param_178': 0.20403459435532545, 'param_179': -0.2621883068826154, 'param_180': 0.30143980043470453, 'param_181': 0.3159170665813349, 'param_182': -0.28937070599691905, 'param_183': 0.2562449306139558, 'param_184': 0.07625017663839984, 'param_185': -0.6610143684023144, 'param_186': -0.04966979487094236, 'param_187': -0.3844358045222751, 'param_188': 0.049444779207808764, 'param_189': 1.4890662379370623, 'param_190': -0.23517914436138776, 'param_191': -0.23113984254932007, 'param_192': -0.5185697957473177, 'param_193': -0.48577589119768816, 'param_194': -0.6805862538265783, 'param_195': -0.1804045798249312, 'param_196': -0.2205314637842093, 'param_197': -0.6558665474964782, 'param_198': -0.35322631384551206, 'param_199': 1.033050344449093, 'param_200': 0.37490942473028177, 'param_201': -0.6128200018219281, 'param_202': 0.580775114510184, 'param_203': 0.21213372407170006, 'param_204': 1.045659691956112, 'param_205': -0.24094753367602273, 'param_206': -0.8837564811808023, 'param_207': 0.685155694562015, 'param_208': 0.4295309488668484, 'param_209': -0.49417391128745924, 'param_210': -0.37753688924802864, 'param_211': 0.30568794473852234, 'param_212': 0.6020103054471586, 'param_213': -0.40259155297359195, 'param_214': -1.0178115694830727, 'param_215': -0.250996337931332, 'param_216': 0.725495099854502, 'param_217': -0.5162918075055021, 'param_218': 1.1362576420013362, 'param_219': -1.0973889526390297, 'param_220': 0.15851303283948193, 'param_221': -0.6533376000649165, 'param_222': 0.10069414226314022, 'param_223': 0.011501570038376041, 'param_224': 0.2635417432201601, 'param_225': -0.8568940912300964, 'param_226': 0.7260300682770842, 'param_227': -0.39679926760551076, 'param_228': 0.007139683406386599, 'param_229': -0.3571277322280182, 'param_230': 0.146683741728725, 'param_231': 0.6921579378340708, 'param_232': -1.0043621043235489, 'param_233': -0.33659172987732355, 'param_234': -0.45626006046196865, 'param_235': 0.2025230335931143, 'param_236': -0.18128568103210552, 'param_237': -0.5076205237723606, 'param_238': 1.2320711710916017, 'param_239': 0.34025920530045495, 'param_240': -0.24905915134326162, 'param_241': -0.46802986517792977, 'param_242': 0.06399012906687274, 'param_243': -0.07129892917222658, 'param_244': -0.7733764536028027, 'param_245': 0.3319662622298454, 'param_246': -0.8233469720628415, 'param_247': 0.09303493809190577, 'param_248': -0.8699222054642219, 'param_249': 1.3210570902017418, 'param_250': -0.01291111256413835, 'param_251': -0.8400367520365235, 'param_252': 0.8197513131623482, 'param_253': 1.0575773867662486, 'param_254': 0.6452832597607427, 'param_255': 1.1300682013338403, 'param_256': -0.8817133073789318, 'param_257': 0.23180938243014593, 'param_258': 0.3507039188407277, 'param_259': 0.10760991560457045, 'param_260': -1.0165490756966435, 'param_261': -0.4172825050589388, 'param_262': 0.34173136727005327, 'param_263': -0.46108772129517606, 'param_264': 0.6017932740383829, 'param_265': -0.08356957044453095, 'param_266': -0.5716716241167539, 'param_267': 0.1472513008566243, 'param_268': -0.3607721454035837, 'param_269': -0.10337817127993354, 'param_270': 0.18135643967959947, 'param_271': -1.5172389732359977, 'param_272': 0.17961813979164498, 'param_273': 0.7670976691541336, 'param_274': 1.2340274496250299, 'param_275': 0.7006833076950936, 'param_276': 0.011606561497906398, 'param_277': 0.31384324873424774, 'param_278': 0.5642318389035634, 'param_279': 0.8714635523430632, 'param_280': -0.7190432226399381, 'param_281': 0.811778432605494, 'param_282': 0.33246351282417086, 'param_283': 0.9242188793716584, 'param_284': -1.3107041894824052, 'param_285': -0.7328394002801275, 'param_286': -1.051259029357694, 'param_287': -0.4007685055922863, 'param_288': 0.1542115616880606, 'param_289': 0.39249409084116627, 'param_290': 0.9458328628515722, 'param_291': 0.02963815365123601, 'param_292': -1.2919768625275063, 'param_293': 0.5572328757922826, 'param_294': -0.024512849990897534, 'param_295': -0.7045316773687147, 'param_296': 1.2265225341699026, 'param_297': -0.33108693987799587, 'param_298': 0.3013477757688299, 'param_299': -0.41882693203730237, 'param_300': -0.6026002201182445, 'param_301': 0.4608425185970195, 'param_302': 0.2535626194965537, 'param_303': -0.037095234648079956, 'param_304': 0.276020618296581, 'param_305': 0.6609970101769775, 'param_306': -0.20734708398786816, 'param_307': 0.02249241249284628, 'param_308': 0.13292598286127477, 'param_309': -0.9019517297449102, 'param_310': 1.7278665309882464, 'param_311': 0.7143731610479929, 'param_312': -0.556173937486748, 'param_313': 0.10893590250464102, 'param_314': -0.2877998834989288, 'param_315': -0.05592947088496203, 'param_316': 0.45422047461168, 'param_317': 0.4163122219992639, 'param_318': 0.6251143968376969, 'param_319': 1.304345520413992, 'param_320': 0.12032664616516531, 'param_321': 1.033921229202584, 'param_322': 0.8646076759907086, 'param_323': 0.5808804775234813, 'param_324': 0.6786635797059244, 'param_325': -0.6003658913202083, 'param_326': 0.7495684128823239, 'param_327': 0.9397119523425577, 'param_328': -0.7025688713191998, 'param_329': 0.08475750893704559, 'param_330': 1.575923562359315, 'param_331': -0.5674951086313667, 'param_332': -1.5837601428745685, 'param_333': 0.720972111144059, 'param_334': -0.8756517793285081, 'param_335': 0.5176667517950087, 'param_336': -0.1972928332548496, 'param_337': 0.966936767584821, 'param_338': -0.8958541128206665, 'param_339': -0.5176525420288507, 'param_340': 0.10856762847348911, 'param_341': 0.6550924915795431, 'param_342': -0.5143208371545003, 'param_343': 1.0379094642179698, 'param_344': 0.5407405230930622, 'param_345': 0.39866758267800817, 'param_346': -0.3688550098758705, 'param_347': 0.9172097351764452, 'param_348': 0.28383173322364597, 'param_349': -0.5558434860927646, 'param_350': -1.2469126902589591, 'param_351': -0.18588009516017023, 'param_352': -0.4995904695658966, 'param_353': -0.525627542397711, 'param_354': 0.8543659051436387, 'param_355': -1.2844845217310423, 'param_356': 0.6713445892359942, 'param_357': 0.6364851021144551, 'param_358': -0.09279679266513563, 'param_359': 0.6909798878085285, 'param_360': -0.6980288825370129, 'param_361': -0.6956290518537127, 'param_362': -0.036586260092891676, 'param_363': -0.7349642420324958, 'param_364': -0.8453315429140653, 'param_365': -0.5187384707045504, 'param_366': -0.4852734905541265, 'param_367': -0.2656127514921731, 'param_368': 0.5833730804650692, 'param_369': -0.5438050625665678, 'param_370': 0.4353149735031927, 'param_371': 0.9637280169268729, 'param_372': 0.5441221945278958, 'param_373': 0.40422213605713386, 'param_374': 0.04031337706314808, 'param_375': -0.5521437933251037, 'param_376': 0.23523013499447698, 'param_377': 0.10415045897202369, 'param_378': -0.08304526241628984, 'param_379': 0.9176751082718848, 'param_380': -0.7185854586058551, 'param_381': -0.024634032900625158, 'param_382': -0.25394788730210416, 'param_383': -0.23652053378984927, 'param_384': -0.8786348779582955, 'param_385': -0.5722450621727078, 'param_386': 0.637409474859294, 'param_387': -0.27572022822596565, 'param_388': 0.49231685936096126, 'param_389': -0.544720986793152, 'param_390': -0.7380752607495289, 'param_391': 0.8275022925346223, 'param_392': 0.2272902420401075, 'param_393': 0.49799599273581263, 'param_394': -0.6765255056413777, 'param_395': 0.3461409540754783, 'param_396': 0.3485763970128173, 'param_397': 0.9889837609269141, 'param_398': 0.20930105271352506, 'param_399': 0.7563558023706514, 'param_400': 0.22092601738202422, 'param_401': 0.4352565220810547, 'param_402': -0.4176031139766574, 'param_403': -0.18859303219724155, 'param_404': 1.100439479925135, 'param_405': -1.3857321689437625, 'param_406': 0.17675435122928906, 'param_407': -0.36405953889327836, 'param_408': -0.44024782272847807, 'param_409': 0.9671614778580069, 'param_410': 0.3413219760015833, 'param_411': -0.3553140738972014, 'param_412': -0.5884476310362816, 'param_413': -1.417609300745755, 'param_414': 0.16306399648309133, 'param_415': -1.010211606077246, 'param_416': -0.019517360783561477, 'param_417': -0.7530990611143116, 'param_418': 0.6046558519351124, 'param_419': 0.877805588120629, 'param_420': -0.3253991358641042, 'param_421': 0.9244397122082941, 'param_422': 0.5129961054483902, 'param_423': 1.6093048152735205, 'param_424': 0.7915495037422104, 'param_425': 0.30082574370311965, 'param_426': 0.49659623328638114, 'param_427': -0.6308712957931184, 'param_428': 0.09986707152471164, 'param_429': -0.4136635566170521, 'param_430': 0.09401117157276628, 'param_431': 0.8979031254910224, 'param_432': -0.10336019537565688, 'param_433': 1.6287134881859688, 'param_434': 0.8207484111189944, 'param_435': 0.2577564613172072, 'param_436': 0.9109120830172275, 'param_437': -0.2925564062546173, 'param_438': -0.8588720691789189, 'param_439': 0.23292724182684532, 'param_440': 0.9381651474948041, 'param_441': -1.0946135520313631, 'param_442': -0.13555864677543994, 'param_443': -0.49122848554811505, 'param_444': 0.4799928427848874, 'param_445': 0.3047960241861958, 'param_446': -0.41727903025377167, 'param_447': 1.6909144890540588, 'param_448': -0.5227747830445111, 'param_449': -0.49437918803468417, 'param_450': 0.43271054533181585, 'param_451': -1.6099543313901077, 'param_452': -1.282284793725173, 'param_453': -1.461514626285616, 'param_454': -0.025799218755085063, 'param_455': 0.3507314074178618, 'param_456': 0.3596976054790022, 'param_457': -0.37671024444154, 'param_458': -0.17050598714823773, 'param_459': 0.5053691608143729, 'param_460': 0.7275511833676709, 'param_461': 0.5939240364883842, 'param_462': 0.7337325804653263, 'param_463': 0.047063615281440985, 'param_464': 0.023818631454264327, 'param_465': -0.21951005812168645, 'param_466': -0.10749428166000041, 'param_467': 0.3548199177208038, 'param_468': 0.5771055615530098, 'param_469': -0.4489754793413292, 'param_470': 0.5152274714015528, 'param_471': -0.4793869396863426, 'param_472': -0.7112765851398168, 'param_473': -0.013812138252040862, 'param_474': 0.22350201674840653, 'param_475': -0.033110503712817874, 'param_476': -1.3014756669611636, 'param_477': 0.26293686191252386, 'param_478': -0.4002926227548351, 'param_479': -0.3339467776806986, 'param_480': 0.02430903527821071, 'param_481': 0.39707788290826196, 'param_482': -0.3675308366956451, 'param_483': 0.5823757700602257, 'param_484': -0.29299744147147866, 'param_485': -0.8183555456545357, 'param_486': -0.6466602234663725, 'param_487': 0.425875421780602, 'param_488': 0.6060392002694259, 'param_489': 0.9036682514923906, 'param_490': 0.4445397580790704, 'param_491': -0.13486987487862656, 'param_492': 0.48597317041307075, 'param_493': 0.5520324297890142, 'param_494': 0.5088650330598217, 'param_495': -0.8187864263071278, 'param_496': 0.35764536258482904, 'param_497': -1.2608771060579456, 'param_498': 0.5896632324119855, 'param_499': 0.7182479502542432, 'param_500': 0.7885814404364728, 'param_501': -0.28711453932806874, 'param_502': -0.7554943465717077, 'param_503': -0.7626979423351106, 'param_504': -0.16644621090089506, 'param_505': 0.1979984141179605, 'param_506': -0.3997493895373099, 'param_507': -1.1703134895205602, 'param_508': -0.09004317552845098, 'param_509': 0.024774191709717286, 'param_510': 0.2829034196613307, 'param_511': 0.4634893397945823, 'param_512': -0.5476236804860442, 'param_513': 0.38212790502845095, 'param_514': 0.5464877467677747, 'param_515': -0.008652428435295123, 'param_516': 0.481735423247001, 'param_517': 0.865897943308354, 'param_518': 0.6981621808316758, 'param_519': -1.5355579555802823, 'param_520': -0.2695618634141501, 'param_521': -0.22431007780494427, 'param_522': -0.5813485464800288, 'param_523': -0.020802007604546313, 'param_524': -0.7398863313603015, 'param_525': 0.5644211955073444, 'param_526': 0.2937396447031526, 'param_527': -0.7065773526112178, 'param_528': -0.3161883672948782, 'param_529': 0.7912414574861861, 'param_530': -0.4272496377628374, 'param_531': 0.40672304631557044, 'param_532': -0.1905100494201819, 'param_533': -1.0121039767096325, 'param_534': -0.14741231911324282, 'param_535': -1.5431608450190712, 'param_536': -0.6963599881385454, 'param_537': -0.33627207958270877, 'param_538': 0.2516724749921475, 'param_539': -0.11843775995784944, 'param_540': 0.3209176393007098, 'param_541': -0.15999852326100772, 'param_542': 0.05859004806498458, 'param_543': 1.1689033146971464, 'param_544': -1.0239020683701363, 'param_545': 0.926781776197954, 'param_546': -0.1748602517243032, 'param_547': 0.8373950149435494, 'param_548': -0.19753201876381743, 'param_549': 0.038482988115341676, 'param_550': -0.32340812035535116, 'param_551': 0.4701978627849841, 'param_552': -0.38400025997286025, 'param_553': 0.1649325714513319, 'param_554': 0.24098979190307634, 'param_555': -0.23125002123182004, 'param_556': 0.6548830873654183, 'param_557': -0.4473733730050773, 'param_558': 0.024325599510335305, 'param_559': -0.5607483529084523, 'param_560': -0.0035664053958890385, 'param_561': 0.4291218990698562, 'param_562': -0.9077946830565549, 'param_563': 0.6245464988221023, 'param_564': -0.5136608994546423, 'param_565': 0.8007213955639854, 'param_566': -0.19041561734716117, 'param_567': 0.6318131825538105, 'param_568': 0.5647323750735431, 'param_569': 0.5141211040344915, 'param_570': -0.0162441588868516, 'param_571': -0.9950280402698362, 'param_572': -0.10612112037123911, 'param_573': -0.5589877728844967, 'param_574': -0.07158583715928257, 'param_575': 0.3374877583279554, 'param_576': 0.5229553657335719, 'param_577': -0.4728630726465697, 'param_578': -1.3536957417254536, 'param_579': 1.2056001788478037, 'param_580': 1.1477534040350292, 'param_581': 0.5454701895192242, 'param_582': -1.1269992990402606, 'param_583': -0.15205993070992463, 'param_584': -0.003862447270234881, 'param_585': 0.18458749086410142, 'param_586': -0.1144289642842582, 'param_587': 1.4309374286729706, 'param_588': 0.2854505004967365, 'param_589': 1.5095742367165066, 'param_590': -0.77868917936605, 'param_591': 0.7929305156263502, 'param_592': -0.165471340828516, 'param_593': -1.1163835290938, 'param_594': -0.9408847166305925, 'param_595': -0.09720234781903425, 'param_596': 0.6491947000409048, 'param_597': -0.5699170605460859, 'param_598': -0.0976717477722504, 'param_599': 0.33102164322210426, 'param_600': -1.6458017022807119, 'param_601': -1.332138192350384, 'param_602': 0.49894129896229833, 'param_603': 0.036259102933345666, 'param_604': 0.7204487193980151, 'param_605': 0.8777368153969918, 'param_606': -0.4437096238633178, 'param_607': -0.5557203106561441, 'param_608': -0.009985292914384658, 'param_609': 0.8555827940469865, 'param_610': 0.17860545305332431, 'param_611': -0.2160150313712954, 'param_612': -0.09774509058041936, 'param_613': 0.3983446913530124, 'param_614': -1.47068368732612, 'param_615': 0.8355150761648167, 'param_616': -1.029837069588052, 'param_617': 1.8531225819004584, 'param_618': 1.762368523657118, 'param_619': 0.12929477686743285, 'param_620': 0.1501618115022505, 'param_621': 0.15688026474948025, 'param_622': -0.9736647189372938, 'param_623': 0.12847609078799627, 'param_624': -0.22796185113179446, 'param_625': -0.22539687165567845, 'param_626': 0.1573833709910315, 'param_627': 0.5618913751866725, 'param_628': -1.5755453891666042, 'param_629': -0.8639711959209149, 'param_630': 0.23978559753818773, 'param_631': 1.3415463249736357, 'param_632': 0.22948179440164562, 'param_633': -0.2941025830925752, 'param_634': -0.10617193987626927, 'param_635': 0.43365499445436084, 'param_636': -1.5027517178625707, 'param_637': 0.6436382768190203, 'param_638': 0.08688597482231186, 'param_639': 0.4997739071630214, 'param_640': 0.1604231786048591, 'param_641': -0.29505878742550307, 'param_642': 0.743158182361431, 'param_643': -0.37228782747153844, 'param_644': -0.46414540651088476, 'param_645': -0.19789137655392763, 'param_646': -0.45809982021926965, 'param_647': 0.22313447138424536, 'param_648': 1.2608219897691795, 'param_649': -1.1145989362456836, 'param_650': -0.1692859865520271, 'param_651': -0.2598394776802031, 'param_652': 0.7992499429228759, 'param_653': -0.42693763605630686, 'param_654': -0.5139998891002875, 'param_655': 0.11727174113362482, 'param_656': -0.08563198688782969, 'param_657': 0.8716468541965154, 'param_658': -0.16997724723716057, 'param_659': 0.2890690440539907, 'param_660': 1.031253770766198, 'param_661': 0.7620536232723492, 'param_662': -0.2826268634109166, 'param_663': 0.9598163807564033, 'param_664': 0.2921855618528353, 'param_665': -0.6875094356994245, 'param_666': -1.0368786316995469, 'param_667': -0.05147001804062423, 'param_668': -0.9927863790912186, 'param_669': 0.26783164027810447, 'param_670': 0.07885282733014964, 'param_671': -0.5498482440412378, 'param_672': -0.1478619868679818, 'param_673': 0.03259803248092297, 'param_674': 1.726106117874564, 'param_675': 0.8848813077954603, 'param_676': 0.09769166767805881, 'param_677': -0.6691072725462746, 'param_678': 0.9838864670959935, 'param_679': -0.16461395911225152, 'param_680': -0.12513304728944163, 'param_681': 1.211831321892146, 'param_682': -0.01704126379420745, 'param_683': 0.05669745101282908, 'param_684': -0.1242146147460601, 'param_685': 0.195053365900558, 'param_686': -0.1741207991598741, 'param_687': -0.18527331567270977, 'param_688': -1.2818503426020489, 'param_689': 0.04906319890709687, 'param_690': 0.3584858118323391, 'param_691': -0.5011591707112746, 'param_692': -1.0682278287124451, 'param_693': 0.20445334254104797} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\daiki\\miniconda3\\envs\\env_torch_world_models\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\daiki\\AppData\\Local\\Temp\\ipykernel_2316\\2970998879.py\", line 5, in objective\n",
      "    params[i] = trial.suggest_uniform('param_{}'.format(i), -2.0, 2.0)\n",
      "  File \"c:\\Users\\daiki\\miniconda3\\envs\\env_torch_world_models\\lib\\site-packages\\optuna\\_deprecated.py\", line 113, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\daiki\\miniconda3\\envs\\env_torch_world_models\\lib\\site-packages\\optuna\\trial\\_trial.py\", line 185, in suggest_uniform\n",
      "    return self.suggest_float(name, low, high)\n",
      "  File \"c:\\Users\\daiki\\miniconda3\\envs\\env_torch_world_models\\lib\\site-packages\\optuna\\trial\\_trial.py\", line 161, in suggest_float\n",
      "    suggested_value = self._suggest(name, distribution)\n",
      "  File \"c:\\Users\\daiki\\miniconda3\\envs\\env_torch_world_models\\lib\\site-packages\\optuna\\trial\\_trial.py\", line 615, in _suggest\n",
      "    trial = self._get_latest_trial()\n",
      "  File \"c:\\Users\\daiki\\miniconda3\\envs\\env_torch_world_models\\lib\\site-packages\\optuna\\trial\\_trial.py\", line 690, in _get_latest_trial\n",
      "    latest_trial = copy.deepcopy(self._cached_frozen_trial)\n",
      "  File \"c:\\Users\\daiki\\miniconda3\\envs\\env_torch_world_models\\lib\\copy.py\", line 172, in deepcopy\n",
      "    y = _reconstruct(x, memo, *rv)\n",
      "  File \"c:\\Users\\daiki\\miniconda3\\envs\\env_torch_world_models\\lib\\copy.py\", line 271, in _reconstruct\n",
      "    state = deepcopy(state, memo)\n",
      "  File \"c:\\Users\\daiki\\miniconda3\\envs\\env_torch_world_models\\lib\\copy.py\", line 146, in deepcopy\n",
      "    y = copier(x, memo)\n",
      "  File \"c:\\Users\\daiki\\miniconda3\\envs\\env_torch_world_models\\lib\\copy.py\", line 231, in _deepcopy_dict\n",
      "    y[deepcopy(key, memo)] = deepcopy(value, memo)\n",
      "  File \"c:\\Users\\daiki\\miniconda3\\envs\\env_torch_world_models\\lib\\copy.py\", line 146, in deepcopy\n",
      "    y = copier(x, memo)\n",
      "  File \"c:\\Users\\daiki\\miniconda3\\envs\\env_torch_world_models\\lib\\copy.py\", line 231, in _deepcopy_dict\n",
      "    y[deepcopy(key, memo)] = deepcopy(value, memo)\n",
      "  File \"c:\\Users\\daiki\\miniconda3\\envs\\env_torch_world_models\\lib\\copy.py\", line 172, in deepcopy\n",
      "    y = _reconstruct(x, memo, *rv)\n",
      "  File \"c:\\Users\\daiki\\miniconda3\\envs\\env_torch_world_models\\lib\\copy.py\", line 271, in _reconstruct\n",
      "    state = deepcopy(state, memo)\n",
      "  File \"c:\\Users\\daiki\\miniconda3\\envs\\env_torch_world_models\\lib\\copy.py\", line 146, in deepcopy\n",
      "    y = copier(x, memo)\n",
      "  File \"c:\\Users\\daiki\\miniconda3\\envs\\env_torch_world_models\\lib\\copy.py\", line 231, in _deepcopy_dict\n",
      "    y[deepcopy(key, memo)] = deepcopy(value, memo)\n",
      "KeyboardInterrupt\n",
      "[W 2023-06-19 14:24:44,510] Trial 1 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m sampler \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39msamplers\u001b[39m.\u001b[39mCmaEsSampler()\n\u001b[0;32m      9\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(sampler\u001b[39m=\u001b[39msampler)\n\u001b[1;32m---> 10\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\daiki\\miniconda3\\envs\\env_torch_world_models\\lib\\site-packages\\optuna\\study\\study.py:443\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[0;32m    340\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    341\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    348\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    349\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    350\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    351\u001b[0m \n\u001b[0;32m    352\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    441\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 443\u001b[0m     _optimize(\n\u001b[0;32m    444\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    445\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[0;32m    446\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[0;32m    447\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    448\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    449\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[0;32m    450\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    451\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[0;32m    452\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[0;32m    453\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\daiki\\miniconda3\\envs\\env_torch_world_models\\lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[0;32m     67\u001b[0m             study,\n\u001b[0;32m     68\u001b[0m             func,\n\u001b[0;32m     69\u001b[0m             n_trials,\n\u001b[0;32m     70\u001b[0m             timeout,\n\u001b[0;32m     71\u001b[0m             catch,\n\u001b[0;32m     72\u001b[0m             callbacks,\n\u001b[0;32m     73\u001b[0m             gc_after_trial,\n\u001b[0;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[0;32m     77\u001b[0m         )\n\u001b[0;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\daiki\\miniconda3\\envs\\env_torch_world_models\\lib\\site-packages\\optuna\\study\\_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\daiki\\miniconda3\\envs\\env_torch_world_models\\lib\\site-packages\\optuna\\study\\_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[0;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    250\u001b[0m ):\n\u001b[1;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[0;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\daiki\\miniconda3\\envs\\env_torch_world_models\\lib\\site-packages\\optuna\\study\\_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[0;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[0;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[9], line 5\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m      3\u001b[0m params \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mstandard_cauchy(params_size) \u001b[39m*\u001b[39m \u001b[39m0.1\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(params_size):\n\u001b[1;32m----> 5\u001b[0m     params[i] \u001b[39m=\u001b[39m trial\u001b[39m.\u001b[39;49msuggest_uniform(\u001b[39m'\u001b[39;49m\u001b[39mparam_\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mformat(i), \u001b[39m-\u001b[39;49m\u001b[39m2.0\u001b[39;49m, \u001b[39m2.0\u001b[39;49m)\n\u001b[0;32m      6\u001b[0m \u001b[39mreturn\u001b[39;00m play(params)\n",
      "File \u001b[1;32mc:\\Users\\daiki\\miniconda3\\envs\\env_torch_world_models\\lib\\site-packages\\optuna\\_deprecated.py:113\u001b[0m, in \u001b[0;36mdeprecated_func.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    110\u001b[0m     message \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m text\n\u001b[0;32m    111\u001b[0m warnings\u001b[39m.\u001b[39mwarn(message, \u001b[39mFutureWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m--> 113\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\daiki\\miniconda3\\envs\\env_torch_world_models\\lib\\site-packages\\optuna\\trial\\_trial.py:185\u001b[0m, in \u001b[0;36mTrial.suggest_uniform\u001b[1;34m(self, name, low, high)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[39m@deprecated_func\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m3.0.0\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m6.0.0\u001b[39m\u001b[39m\"\u001b[39m, text\u001b[39m=\u001b[39m_suggest_deprecated_msg\u001b[39m.\u001b[39mformat(args\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m    166\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msuggest_uniform\u001b[39m(\u001b[39mself\u001b[39m, name: \u001b[39mstr\u001b[39m, low: \u001b[39mfloat\u001b[39m, high: \u001b[39mfloat\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mfloat\u001b[39m:\n\u001b[0;32m    167\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Suggest a value for the continuous parameter.\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \n\u001b[0;32m    169\u001b[0m \u001b[39m    The value is sampled from the range :math:`[\\\\mathsf{low}, \\\\mathsf{high})`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[39m        A suggested float value.\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msuggest_float(name, low, high)\n",
      "File \u001b[1;32mc:\\Users\\daiki\\miniconda3\\envs\\env_torch_world_models\\lib\\site-packages\\optuna\\trial\\_trial.py:161\u001b[0m, in \u001b[0;36mTrial.suggest_float\u001b[1;34m(self, name, low, high, step, log)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Suggest a value for the floating point parameter.\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \n\u001b[0;32m     87\u001b[0m \u001b[39mExample:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[39m    :ref:`configurations` tutorial describes more details and flexible usages.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    160\u001b[0m distribution \u001b[39m=\u001b[39m FloatDistribution(low, high, log\u001b[39m=\u001b[39mlog, step\u001b[39m=\u001b[39mstep)\n\u001b[1;32m--> 161\u001b[0m suggested_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_suggest(name, distribution)\n\u001b[0;32m    162\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_distribution(name, distribution)\n\u001b[0;32m    163\u001b[0m \u001b[39mreturn\u001b[39;00m suggested_value\n",
      "File \u001b[1;32mc:\\Users\\daiki\\miniconda3\\envs\\env_torch_world_models\\lib\\site-packages\\optuna\\trial\\_trial.py:615\u001b[0m, in \u001b[0;36mTrial._suggest\u001b[1;34m(self, name, distribution)\u001b[0m\n\u001b[0;32m    612\u001b[0m storage \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstorage\n\u001b[0;32m    613\u001b[0m trial_id \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_trial_id\n\u001b[1;32m--> 615\u001b[0m trial \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_latest_trial()\n\u001b[0;32m    617\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m trial\u001b[39m.\u001b[39mdistributions:\n\u001b[0;32m    618\u001b[0m     \u001b[39m# No need to sample if already suggested.\u001b[39;00m\n\u001b[0;32m    619\u001b[0m     distributions\u001b[39m.\u001b[39mcheck_distribution_compatibility(trial\u001b[39m.\u001b[39mdistributions[name], distribution)\n",
      "File \u001b[1;32mc:\\Users\\daiki\\miniconda3\\envs\\env_torch_world_models\\lib\\site-packages\\optuna\\trial\\_trial.py:690\u001b[0m, in \u001b[0;36mTrial._get_latest_trial\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_latest_trial\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m FrozenTrial:\n\u001b[0;32m    689\u001b[0m     \u001b[39m# TODO(eukaryo): Remove this method after `system_attrs` property is removed.\u001b[39;00m\n\u001b[1;32m--> 690\u001b[0m     latest_trial \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39;49mdeepcopy(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cached_frozen_trial)\n\u001b[0;32m    691\u001b[0m     latest_trial\u001b[39m.\u001b[39msystem_attrs \u001b[39m=\u001b[39m _LazyTrialSystemAttrs(  \u001b[39m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m    692\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_trial_id, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstorage\n\u001b[0;32m    693\u001b[0m     )\n\u001b[0;32m    694\u001b[0m     \u001b[39mreturn\u001b[39;00m latest_trial\n",
      "File \u001b[1;32mc:\\Users\\daiki\\miniconda3\\envs\\env_torch_world_models\\lib\\copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 y \u001b[39m=\u001b[39m x\n\u001b[0;32m    171\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m                 y \u001b[39m=\u001b[39m _reconstruct(x, memo, \u001b[39m*\u001b[39;49mrv)\n\u001b[0;32m    174\u001b[0m \u001b[39m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m x:\n",
      "File \u001b[1;32mc:\\Users\\daiki\\miniconda3\\envs\\env_torch_world_models\\lib\\copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    270\u001b[0m     \u001b[39mif\u001b[39;00m deep:\n\u001b[1;32m--> 271\u001b[0m         state \u001b[39m=\u001b[39m deepcopy(state, memo)\n\u001b[0;32m    272\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(y, \u001b[39m'\u001b[39m\u001b[39m__setstate__\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    273\u001b[0m         y\u001b[39m.\u001b[39m__setstate__(state)\n",
      "File \u001b[1;32mc:\\Users\\daiki\\miniconda3\\envs\\env_torch_world_models\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[39m=\u001b[39m _deepcopy_dispatch\u001b[39m.\u001b[39mget(\u001b[39mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[39mif\u001b[39;00m copier \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[39m=\u001b[39m copier(x, memo)\n\u001b[0;32m    147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39mtype\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\daiki\\miniconda3\\envs\\env_torch_world_models\\lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[39mid\u001b[39m(x)] \u001b[39m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m x\u001b[39m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[39m=\u001b[39m deepcopy(value, memo)\n\u001b[0;32m    232\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "File \u001b[1;32mc:\\Users\\daiki\\miniconda3\\envs\\env_torch_world_models\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[39m=\u001b[39m _deepcopy_dispatch\u001b[39m.\u001b[39mget(\u001b[39mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[39mif\u001b[39;00m copier \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[39m=\u001b[39m copier(x, memo)\n\u001b[0;32m    147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39mtype\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\daiki\\miniconda3\\envs\\env_torch_world_models\\lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[39mid\u001b[39m(x)] \u001b[39m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m x\u001b[39m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[39m=\u001b[39m deepcopy(value, memo)\n\u001b[0;32m    232\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "File \u001b[1;32mc:\\Users\\daiki\\miniconda3\\envs\\env_torch_world_models\\lib\\copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 y \u001b[39m=\u001b[39m x\n\u001b[0;32m    171\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m                 y \u001b[39m=\u001b[39m _reconstruct(x, memo, \u001b[39m*\u001b[39;49mrv)\n\u001b[0;32m    174\u001b[0m \u001b[39m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m x:\n",
      "File \u001b[1;32mc:\\Users\\daiki\\miniconda3\\envs\\env_torch_world_models\\lib\\copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    270\u001b[0m     \u001b[39mif\u001b[39;00m deep:\n\u001b[1;32m--> 271\u001b[0m         state \u001b[39m=\u001b[39m deepcopy(state, memo)\n\u001b[0;32m    272\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(y, \u001b[39m'\u001b[39m\u001b[39m__setstate__\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    273\u001b[0m         y\u001b[39m.\u001b[39m__setstate__(state)\n",
      "File \u001b[1;32mc:\\Users\\daiki\\miniconda3\\envs\\env_torch_world_models\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[39m=\u001b[39m _deepcopy_dispatch\u001b[39m.\u001b[39mget(\u001b[39mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[39mif\u001b[39;00m copier \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[39m=\u001b[39m copier(x, memo)\n\u001b[0;32m    147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39mtype\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\daiki\\miniconda3\\envs\\env_torch_world_models\\lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[39mid\u001b[39m(x)] \u001b[39m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m x\u001b[39m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[39m=\u001b[39m deepcopy(value, memo)\n\u001b[0;32m    232\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    params_size = (z_size + h_size) * a_size + a_size\n",
    "    params = np.random.standard_cauchy(params_size) * 0.1\n",
    "    for i in range(params_size):\n",
    "        params[i] = trial.suggest_uniform('param_{}'.format(i), -2.0, 2.0)\n",
    "    return play(params)\n",
    "\n",
    "sampler = optuna.samplers.CmaEsSampler()\n",
    "study = optuna.create_study(sampler=sampler)\n",
    "study.optimize(objective, n_trials=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best trial:')\n",
    "trial = study.best_trial\n",
    " \n",
    "print('  Value: {}'.format(trial.value))\n",
    " \n",
    "print('  Params: ')\n",
    "for key, value in trial.params.items():\n",
    "    print('    {}: {}'.format(key, value))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optuna 分散"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\daiki\\miniconda3\\envs\\env_torch_world_models\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-21 08:35:08,430] A new study created in RDB with name: example2_postgress\n",
      "C:\\Users\\daiki\\AppData\\Local\\Temp\\ipykernel_9940\\856990969.py:3: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  x = trial.suggest_uniform('x', -10, 10)\n",
      "[I 2023-06-21 08:35:08,499] Trial 0 finished with value: 3.2118873811723243 and parameters: {'x': 0.20782607396147945}. Best is trial 0 with value: 3.2118873811723243.\n",
      "[I 2023-06-21 08:35:08,548] Trial 1 finished with value: 35.10170597237097 and parameters: {'x': 7.924669271138345}. Best is trial 0 with value: 3.2118873811723243.\n",
      "[I 2023-06-21 08:35:08,596] Trial 2 finished with value: 6.257541310369877 and parameters: {'x': 4.501507807377358}. Best is trial 0 with value: 3.2118873811723243.\n",
      "[I 2023-06-21 08:35:08,650] Trial 3 finished with value: 32.30927957184839 and parameters: {'x': 7.684125224856363}. Best is trial 0 with value: 3.2118873811723243.\n",
      "[I 2023-06-21 08:35:08,713] Trial 4 finished with value: 88.22695202387543 and parameters: {'x': -7.392920313931947}. Best is trial 0 with value: 3.2118873811723243.\n",
      "[I 2023-06-21 08:35:08,766] Trial 5 finished with value: 6.2126172542609845 and parameters: {'x': 4.49251223753485}. Best is trial 0 with value: 3.2118873811723243.\n",
      "[I 2023-06-21 08:35:08,815] Trial 6 finished with value: 138.599429056933 and parameters: {'x': -9.772825873889964}. Best is trial 0 with value: 3.2118873811723243.\n",
      "[I 2023-06-21 08:35:08,864] Trial 7 finished with value: 19.34176617615986 and parameters: {'x': 6.397927486459942}. Best is trial 0 with value: 3.2118873811723243.\n",
      "[I 2023-06-21 08:35:08,915] Trial 8 finished with value: 80.66027517795987 and parameters: {'x': -6.981106567565039}. Best is trial 0 with value: 3.2118873811723243.\n",
      "[I 2023-06-21 08:35:08,963] Trial 9 finished with value: 2.3490756015829017 and parameters: {'x': 3.532669436500546}. Best is trial 9 with value: 2.3490756015829017.\n",
      "[I 2023-06-21 08:35:09,016] Trial 10 finished with value: 3.3719649812445844 and parameters: {'x': 0.1637089061794738}. Best is trial 9 with value: 2.3490756015829017.\n",
      "[I 2023-06-21 08:35:09,069] Trial 11 finished with value: 3.1632843281082894 and parameters: {'x': 0.2214375669917322}. Best is trial 9 with value: 2.3490756015829017.\n",
      "[I 2023-06-21 08:35:09,121] Trial 12 finished with value: 0.0007221423742855068 and parameters: {'x': 2.0268727068656194}. Best is trial 12 with value: 0.0007221423742855068.\n",
      "[I 2023-06-21 08:35:09,174] Trial 13 finished with value: 1.2276664227146556 and parameters: {'x': 3.1080010932822475}. Best is trial 12 with value: 0.0007221423742855068.\n",
      "[I 2023-06-21 08:35:09,231] Trial 14 finished with value: 60.92732353111127 and parameters: {'x': 9.805595655112509}. Best is trial 12 with value: 0.0007221423742855068.\n",
      "[I 2023-06-21 08:35:09,289] Trial 15 finished with value: 0.14158097843065906 and parameters: {'x': 2.3762724789705714}. Best is trial 12 with value: 0.0007221423742855068.\n",
      "[I 2023-06-21 08:35:09,341] Trial 16 finished with value: 19.77141586185686 and parameters: {'x': -2.4465060285416076}. Best is trial 12 with value: 0.0007221423742855068.\n",
      "[I 2023-06-21 08:35:09,407] Trial 17 finished with value: 0.0002608334541288134 and parameters: {'x': 1.9838496608664458}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:09,466] Trial 18 finished with value: 12.865422355223728 and parameters: {'x': -1.5868401630437519}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:09,525] Trial 19 finished with value: 26.302621654499628 and parameters: {'x': -3.1286081595789343}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:09,579] Trial 20 finished with value: 0.08308081549933126 and parameters: {'x': 1.7117625709604471}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:09,639] Trial 21 finished with value: 0.1639140321940031 and parameters: {'x': 1.595137020469884}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:09,698] Trial 22 finished with value: 0.07810747190599673 and parameters: {'x': 1.7205228597792}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:09,767] Trial 23 finished with value: 10.296196227845535 and parameters: {'x': 5.2087686466689265}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:09,835] Trial 24 finished with value: 0.20127163055281816 and parameters: {'x': 2.448633068947016}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:09,924] Trial 25 finished with value: 13.69108991357498 and parameters: {'x': -1.7001472826868635}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:09,976] Trial 26 finished with value: 2.6025751754848905 and parameters: {'x': 3.6132498800511006}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:10,028] Trial 27 finished with value: 0.516240063752697 and parameters: {'x': 1.2815015213984813}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:10,079] Trial 28 finished with value: 9.121999552875286 and parameters: {'x': -1.020264815024551}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:10,131] Trial 29 finished with value: 5.736246177027915 and parameters: {'x': -0.39504617429975974}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:10,186] Trial 30 finished with value: 13.265840859334688 and parameters: {'x': 5.642230204055571}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:10,242] Trial 31 finished with value: 0.3628883989634558 and parameters: {'x': 1.3975978096292678}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:10,293] Trial 32 finished with value: 0.35860005059905864 and parameters: {'x': 1.4011677608886954}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:10,344] Trial 33 finished with value: 2.9273387599511813 and parameters: {'x': 3.710946743750717}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:10,395] Trial 34 finished with value: 2.504229963762021 and parameters: {'x': 0.4175241032603305}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:10,447] Trial 35 finished with value: 0.3676654304456835 and parameters: {'x': 2.6063542120293084}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:10,499] Trial 36 finished with value: 5.679352965564471 and parameters: {'x': 4.383139308887433}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:10,551] Trial 37 finished with value: 17.13168520053036 and parameters: {'x': 6.13904399596457}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:10,604] Trial 38 finished with value: 7.6015612583871395 and parameters: {'x': 4.7570928998470725}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:10,660] Trial 39 finished with value: 0.3312894935025596 and parameters: {'x': 2.5755775304010395}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:10,714] Trial 40 finished with value: 5.908040303819341 and parameters: {'x': 4.430646067163901}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:10,765] Trial 41 finished with value: 0.020526945943714965 and parameters: {'x': 2.1432722790483734}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:10,816] Trial 42 finished with value: 0.8484257953521565 and parameters: {'x': 1.0788996822537968}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:10,867] Trial 43 finished with value: 0.10083019264951844 and parameters: {'x': 2.3175377027212964}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:10,922] Trial 44 finished with value: 4.856780497815642 and parameters: {'x': -0.20381044961122763}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:10,975] Trial 45 finished with value: 2.667840725654008 and parameters: {'x': 3.633352602977694}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:11,027] Trial 46 finished with value: 1.3738007917992998 and parameters: {'x': 0.8279075156800553}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:11,082] Trial 47 finished with value: 21.84553072002325 and parameters: {'x': 6.673920273177886}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:11,134] Trial 48 finished with value: 0.0005131566871089884 and parameters: {'x': 2.022652961994163}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:11,189] Trial 49 finished with value: 1.9236854295270287 and parameters: {'x': 0.6130301266692817}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:11,241] Trial 50 finished with value: 0.7860154022997453 and parameters: {'x': 2.886575096819071}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:11,293] Trial 51 finished with value: 0.003621325226424246 and parameters: {'x': 1.9398225521775454}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:11,348] Trial 52 finished with value: 0.038247114173883885 and parameters: {'x': 2.195568694258268}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:11,399] Trial 53 finished with value: 2.5564118581881834 and parameters: {'x': 3.5988783125016686}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:11,451] Trial 54 finished with value: 0.01603217165657456 and parameters: {'x': 2.1266182121836135}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:11,505] Trial 55 finished with value: 2.1867630050427858 and parameters: {'x': 0.5212292249835386}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:11,557] Trial 56 finished with value: 1.349675978086336 and parameters: {'x': 3.161755558663842}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:11,612] Trial 57 finished with value: 5.507319314423541 and parameters: {'x': -0.346767844168558}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:11,663] Trial 58 finished with value: 0.0017025633443518986 and parameters: {'x': 1.958737870336689}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:11,715] Trial 59 finished with value: 0.04333135622717468 and parameters: {'x': 1.7918381489629411}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:11,768] Trial 60 finished with value: 1.0740415096641034 and parameters: {'x': 3.0363597395036646}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:11,824] Trial 61 finished with value: 0.0063595784141854475 and parameters: {'x': 2.0797469649214655}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:11,878] Trial 62 finished with value: 0.7455977447881607 and parameters: {'x': 1.13651998008746}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:11,931] Trial 63 finished with value: 4.3519555837179915 and parameters: {'x': 4.086134124096049}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:11,983] Trial 64 finished with value: 0.01175194259478499 and parameters: {'x': 1.8915936229053614}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:12,038] Trial 65 finished with value: 1.0813136812215696 and parameters: {'x': 3.039862337630116}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:12,092] Trial 66 finished with value: 3.117613962685411 and parameters: {'x': 0.2343233697289271}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:12,145] Trial 67 finished with value: 0.055315280576973935 and parameters: {'x': 1.7648079921065047}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:12,196] Trial 68 finished with value: 1.1854095860224818 and parameters: {'x': 0.9112348343088479}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:12,249] Trial 69 finished with value: 7.376504535712885 and parameters: {'x': -0.7159721161515789}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:12,302] Trial 70 finished with value: 4.064082489429093 and parameters: {'x': 4.015956966164976}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:12,358] Trial 71 finished with value: 0.002129925132261762 and parameters: {'x': 2.046151111928769}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:12,413] Trial 72 finished with value: 0.046346879392274734 and parameters: {'x': 1.7847167461406375}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:12,465] Trial 73 finished with value: 0.8974737133351696 and parameters: {'x': 2.9473508924021603}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:12,517] Trial 74 finished with value: 0.533622801504464 and parameters: {'x': 1.2695050982351321}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:12,572] Trial 75 finished with value: 3.2640804094483387 and parameters: {'x': 0.19332337994638937}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:12,626] Trial 76 finished with value: 0.20965861000059507 and parameters: {'x': 2.4578849309603834}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:12,679] Trial 77 finished with value: 1.5670005514549372 and parameters: {'x': 0.7482010738721105}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:12,734] Trial 78 finished with value: 1.8959064497377223 and parameters: {'x': 3.3769191878021463}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:12,791] Trial 79 finished with value: 8.949479691960963 and parameters: {'x': 4.991568099168221}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:12,879] Trial 80 finished with value: 0.18443668165540886 and parameters: {'x': 1.570539080176777}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:12,931] Trial 81 finished with value: 0.015148366974831236 and parameters: {'x': 2.123078702360852}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:12,988] Trial 82 finished with value: 0.5383217792581391 and parameters: {'x': 2.733704149680332}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:13,042] Trial 83 finished with value: 0.0018364086955998985 and parameters: {'x': 2.042853339375128}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:13,094] Trial 84 finished with value: 0.5127488081034657 and parameters: {'x': 1.2839351928048233}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:13,149] Trial 85 finished with value: 0.4616997983136492 and parameters: {'x': 2.679484950763186}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:13,239] Trial 86 finished with value: 0.003094529390309895 and parameters: {'x': 1.9443715055901214}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:13,292] Trial 87 finished with value: 2.2701196297733506 and parameters: {'x': 3.5066916173435594}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:13,345] Trial 88 finished with value: 3.7634425322657554 and parameters: {'x': 0.06004058489210773}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:13,406] Trial 89 finished with value: 0.169201944613504 and parameters: {'x': 2.411341639775873}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:13,461] Trial 90 finished with value: 1.7524534774982086 and parameters: {'x': 0.6761973419356613}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:13,514] Trial 91 finished with value: 0.004427263086971241 and parameters: {'x': 1.9334623182927806}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:13,566] Trial 92 finished with value: 0.2501731149000858 and parameters: {'x': 1.4998269150583112}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:13,620] Trial 93 finished with value: 0.01225908680058853 and parameters: {'x': 2.1107207604769247}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:13,673] Trial 94 finished with value: 1.0937375092731514 and parameters: {'x': 0.9541809385590874}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:13,730] Trial 95 finished with value: 1.368174434954769 and parameters: {'x': 3.1696898883698914}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:13,784] Trial 96 finished with value: 3.78254134716257 and parameters: {'x': 3.9448756636768763}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:13,839] Trial 97 finished with value: 0.33707720975371364 and parameters: {'x': 2.5805835079932202}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:13,894] Trial 98 finished with value: 0.22045380469534392 and parameters: {'x': 1.5304749157975222}. Best is trial 17 with value: 0.0002608334541288134.\n",
      "[I 2023-06-21 08:35:13,946] Trial 99 finished with value: 5.5477283090187235e-05 and parameters: {'x': 2.00744830739767}. Best is trial 99 with value: 5.5477283090187235e-05.\n"
     ]
    }
   ],
   "source": [
    "import optuna \n",
    "def objective(trial):\n",
    "    x = trial.suggest_uniform('x', -10, 10)\n",
    "    return (x - 2) ** 2 \n",
    "\n",
    "# DATABASE_URI = 'postgresql://{user}:{password}@{host}:{port}/{database_name}'\n",
    "DATABASE_URI = 'sqlite:///optuna_test1.db'\n",
    "study_name = 'example2_postgress'\n",
    "\n",
    "study = optuna.create_study(\n",
    "    study_name=study_name,\n",
    "    storage=DATABASE_URI,\n",
    "    load_if_exists=True\n",
    ")\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用可能なCPUの数を確認\n",
    "import os \n",
    "from multiprocessing import Process\n",
    "max_cpu = os.cpu_count()\n",
    "max_cpu # 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    x = trial.suggest_uniform('x', -10, 10)\n",
    "    return (x - 2) ** 2 \n",
    "\n",
    "def optimize(study_name, storage, n_trials):\n",
    "    study = optuna.create_study(\n",
    "        study_name=study_name,\n",
    "        storage=storage,\n",
    "        load_if_exists=True\n",
    "    )\n",
    "    study.optimize(objective, n_trials=n_trials)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## jupyter notebookだと動かない可能性がある\n",
    "# 並列化処理は if __name__ == '__main__': の中で書かないと動かない\n",
    "if __name__ == '__main__':\n",
    "    # DATABASE_URI = 'postgresql://{user}:{password}@{host}:{port}/{database_name}'\n",
    "    DATABASE_URI = 'sqlite:///optuna_test2.db'\n",
    "    study_name = 'example3_distributed'\n",
    "\n",
    "    n_trials = 300\n",
    "    concurrency = 2  \n",
    "    # max_cpuより使うCPUの数が多くないことを確認\n",
    "    assert concurrency <= max_cpu\n",
    "    n_trials_per_cpu = n_trials / concurrency\n",
    "\n",
    "\n",
    "    # 並列化\n",
    "    workers = [Process(target=optimize, args=(study_name, DATABASE_URI, n_trials_per_cpu)) for _ in range(concurrency)]\n",
    "    for worker in workers:\n",
    "        worker.start()\n",
    "\n",
    "    for worker in workers:\n",
    "        worker.join()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習環境作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.VAE import VAE\n",
    "from models.MDN_RNN import MDNRNN\n",
    "from gym.envs.box2d.car_dynamics import Car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_size = 32\n",
    "a_size = 3\n",
    "h_size = 256\n",
    "\n",
    "params_size = (z_size + h_size) * a_size + a_size\n",
    "\n",
    "rewards_through_gens = []\n",
    "generation = 1\n",
    "\n",
    "def reshape_state(state):\n",
    "    HEIGHT = 64\n",
    "    WIDTH = 64\n",
    "    state = state[0:84, :, :]\n",
    "    state = np.array(Image.fromarray(state).resize((HEIGHT, WIDTH)))\n",
    "    state = state / 255.0\n",
    "    return state\n",
    "\n",
    "def decide_action(v, m, c, state, hidden, cell, device, use_world_model=False):\n",
    "    hidden = hidden.reshape(-1)\n",
    "    cell = cell.reshape(-1)\n",
    "\n",
    "    state = reshape_state(state)\n",
    "    state = np.moveaxis(state, 2, 0)\n",
    "    state = np.reshape(state, (-1, 3, 64, 64))\n",
    "    state = torch.tensor(state, dtype=torch.float32).to(device)\n",
    "    z, _, _ = v.encode(state)\n",
    "    z = z.detach().numpy()\n",
    "    z = z.reshape(-1)\n",
    "    a = c.forward(z, hidden)\n",
    "    z = torch.tensor(z, dtype=torch.float32).to(device).reshape(1, 1, -1)\n",
    "    a = torch.tensor(a, dtype=torch.float32).to(device).reshape(1, 1, -1)\n",
    "    hidden = torch.tensor(hidden, dtype=torch.float32).to(device).reshape(1, 1, -1)\n",
    "    cell = torch.tensor(cell, dtype=torch.float32).to(device).reshape(1, 1, -1)\n",
    "    pi, mu, logsigma, next_hidden, next_cell = m(z, a, hidden, cell)\n",
    "\n",
    "    pi, mu, logsigma = pi.detach().numpy().reshape(-1), mu.detach().numpy().reshape(-1), logsigma.detach().numpy().reshape(-1)\n",
    "    next_hidden, next_cell = next_hidden.detach().numpy().reshape(-1), next_cell.detach().numpy().reshape(-1)\n",
    "    a = a.detach().numpy().reshape(-1)\n",
    "    if use_world_model:\n",
    "        return a, pi, mu, logsigma, next_hidden, next_cell\n",
    "    else:\n",
    "        return a, next_hidden, next_cell\n",
    "\n",
    "def play(params, seed_num=0):\n",
    "    with torch.no_grad():\n",
    "        device = torch.device('cpu')\n",
    "        vae = VAE()\n",
    "        checkpoint = torch.load('vae.pth')\n",
    "        vae.load_state_dict(checkpoint['model_state_dict'])\n",
    "        vae = vae.eval()\n",
    "        vae.to(device)\n",
    "\n",
    "        mdnrnn = MDNRNN().to(device)\n",
    "        checkpoint = torch.load('mdnrnn.pth')\n",
    "        mdnrnn.load_state_dict(checkpoint['model_state_dict'])\n",
    "        mdnrnn = mdnrnn.eval()\n",
    "        mdnrnn.to(device)\n",
    "\n",
    "        controller = Controller(z_size, a_size, h_size, params)\n",
    "\n",
    "        env = gym.make('CarRacing-v2', render_mode='rgb_array', domain_randomize=True)\n",
    "        env.reset(seed=seed_num)\n",
    "\n",
    "        _NUM_TRIALS = 3\n",
    "        agent_reward = 0\n",
    "\n",
    "        for trial in range(_NUM_TRIALS):\n",
    "            state, _ = env.reset()\n",
    "            np.random.seed(int(str(time.time()*1000000)[10:13]))\n",
    "            position = np.random.randint(len(env.track))\n",
    "            env.car = Car(env.world, *env.track[position][1:4])\n",
    "\n",
    "            hidden = torch.zeros(1, 1, 256).float().to(device)\n",
    "            cell = torch.zeros(1, 1, 256).float().to(device)\n",
    "\n",
    "            total_reward = 0.0\n",
    "            steps = 0\n",
    "\n",
    "            while True:\n",
    "                action, hidden, cell = decide_action(vae, mdnrnn, controller, state, hidden, cell, device)\n",
    "                state, reward, done, _, _ = env.step(action)\n",
    "                total_reward += reward\n",
    "                steps += 1\n",
    "                if steps > 3000 or done:\n",
    "                    break\n",
    "        \n",
    "            agent_reward += total_reward\n",
    "        \n",
    "        env.close()\n",
    "        return -(agent_reward / _NUM_TRIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    params_size = (z_size + h_size) * a_size + a_size\n",
    "    params = np.random.standard_cauchy(params_size) * 0.1\n",
    "    for i in range(params_size):\n",
    "        params[i] = trial.suggest_uniform('param_{}'.format(i), -2.0, 2.0)\n",
    "    return play(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "867"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 最適化結果の取り出し\n",
    "DATABASE_URI = 'sqlite:///controller.db'\n",
    "study_name = 'controller_params1'\n",
    "study = optuna.load_study(study_name=study_name, storage=DATABASE_URI)\n",
    "len(study.best_params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## play Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.VAE import VAE\n",
    "from models.MDN_RNN import MDNRNN\n",
    "from models.controller import Controller\n",
    "from gym.envs.box2d.car_dynamics import Car\n",
    "import optuna\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CarRacing-v2', render_mode='rgb_array', domain_randomize=True)\n",
    "state_list = []\n",
    "state, _ = env.reset()\n",
    "np.random.seed(int(str(time.time()*1000000)[10:13]))\n",
    "position = np.random.randint(len(env.track))\n",
    "env.car = Car(env.world, *env.track[position][1:4])\n",
    "for i in range(3000):\n",
    "    # random\n",
    "    state, _, _, _, _ = env.step(env.action_space.sample())\n",
    "    state_list.append(state)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'state_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mimageio\u001b[39;00m\n\u001b[0;32m      3\u001b[0m images \u001b[39m=\u001b[39m []\n\u001b[1;32m----> 4\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(state_list)):\n\u001b[0;32m      5\u001b[0m     images\u001b[39m.\u001b[39mappend(state_list[i])\n\u001b[0;32m      6\u001b[0m imageio\u001b[39m.\u001b[39mmimsave(\u001b[39m'\u001b[39m\u001b[39mrandom.gif\u001b[39m\u001b[39m'\u001b[39m, images, duration\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'state_list' is not defined"
     ]
    }
   ],
   "source": [
    "# make gif from state_list\n",
    "import imageio\n",
    "images = []\n",
    "for i in range(len(state_list)):\n",
    "    images.append(state_list[i])\n",
    "imageio.mimsave('random.gif', images, duration=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_size = 32\n",
    "a_size = 3\n",
    "h_size = 256\n",
    "\n",
    "params_size = (z_size + h_size) * a_size + a_size\n",
    "\n",
    "rewards_through_gens = []\n",
    "generation = 1\n",
    "\n",
    "def reshape_state(state):\n",
    "    HEIGHT = 64\n",
    "    WIDTH = 64\n",
    "    state = state[0:84, :, :]\n",
    "    state = np.array(Image.fromarray(state).resize((HEIGHT, WIDTH)))\n",
    "    state = state / 255.0\n",
    "    return state\n",
    "\n",
    "def decide_action(v, m, c, state, hidden, cell, device, use_world_model=False):\n",
    "    hidden = hidden.reshape(-1)\n",
    "    cell = cell.reshape(-1)\n",
    "\n",
    "    state = reshape_state(state)\n",
    "    state = np.moveaxis(state, 2, 0)\n",
    "    state = np.reshape(state, (-1, 3, 64, 64))\n",
    "    state = torch.tensor(state, dtype=torch.float32).to(device)\n",
    "    z, _, _ = v.encode(state)\n",
    "    z = z.detach().numpy()\n",
    "    z = z.reshape(-1)\n",
    "    a = c.forward(z, hidden)\n",
    "    z = torch.tensor(z, dtype=torch.float32).to(device).reshape(1, 1, -1)\n",
    "    a = torch.tensor(a, dtype=torch.float32).to(device).reshape(1, 1, -1)\n",
    "    hidden = torch.tensor(hidden, dtype=torch.float32).to(device).reshape(1, 1, -1)\n",
    "    cell = torch.tensor(cell, dtype=torch.float32).to(device).reshape(1, 1, -1)\n",
    "    pi, mu, logsigma, next_hidden, next_cell = m(z, a, hidden, cell)\n",
    "\n",
    "    pi, mu, logsigma = pi.detach().numpy().reshape(-1), mu.detach().numpy().reshape(-1), logsigma.detach().numpy().reshape(-1)\n",
    "    next_hidden, next_cell = next_hidden.detach().numpy().reshape(-1), next_cell.detach().numpy().reshape(-1)\n",
    "    a = a.detach().numpy().reshape(-1)\n",
    "    if use_world_model:\n",
    "        return a, pi, mu, logsigma, next_hidden, next_cell\n",
    "    else:\n",
    "        return a, next_hidden, next_cell\n",
    "\n",
    "def play(params, seed_num=0):\n",
    "    with torch.no_grad():\n",
    "        device = torch.device('cpu')\n",
    "        vae = VAE()\n",
    "        checkpoint = torch.load('vae.pth')\n",
    "        vae.load_state_dict(checkpoint['model_state_dict'])\n",
    "        vae = vae.eval()\n",
    "        vae.to(device)\n",
    "\n",
    "        mdnrnn = MDNRNN().to(device)\n",
    "        checkpoint = torch.load('mdnrnn.pth')\n",
    "        mdnrnn.load_state_dict(checkpoint['model_state_dict'])\n",
    "        mdnrnn = mdnrnn.eval()\n",
    "        mdnrnn.to(device)\n",
    "\n",
    "        controller = Controller(z_size, a_size, h_size, params)\n",
    "\n",
    "        env = gym.make('CarRacing-v2', render_mode='rgb_array', domain_randomize=True)\n",
    "        env.reset(seed=seed_num)\n",
    "\n",
    "        _NUM_TRIALS = 3\n",
    "        agent_reward = 0\n",
    "\n",
    "        for trial in range(_NUM_TRIALS):\n",
    "            save_frame = []\n",
    "            state, _ = env.reset()\n",
    "            np.random.seed(int(str(time.time()*1000000)[10:13]))\n",
    "            position = np.random.randint(len(env.track))\n",
    "            env.car = Car(env.world, *env.track[position][1:4])\n",
    "\n",
    "            hidden = torch.zeros(1, 1, 256).float().to(device)\n",
    "            cell = torch.zeros(1, 1, 256).float().to(device)\n",
    "\n",
    "            total_reward = 0.0\n",
    "            steps = 0\n",
    "\n",
    "            while True:\n",
    "                action, hidden, cell = decide_action(vae, mdnrnn, controller, state, hidden, cell, device)\n",
    "                state, reward, done, _, _ = env.step(action)\n",
    "                # print(action)\n",
    "                # print(done)\n",
    "                save_frame.append(state)\n",
    "                total_reward += reward\n",
    "                steps += 1\n",
    "                if steps > 3000 or done:\n",
    "                    break\n",
    "                # if done:\n",
    "                    # break\n",
    "        \n",
    "            agent_reward += total_reward\n",
    "            print('trial: {}, total_reward: {}'.format(trial, total_reward))\n",
    "            images = []\n",
    "            for i in range(len(save_frame)):\n",
    "                images.append(save_frame[i])\n",
    "            imageio.mimsave(f'traial_{trial+1}.gif', images, duration=20)\n",
    "        \n",
    "        env.close()\n",
    "\n",
    "\n",
    "        return -(agent_reward / _NUM_TRIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最適化結果の取り出し\n",
    "DATABASE_URI = 'sqlite:///controller.db'\n",
    "study_name = 'controller_params1'\n",
    "study = optuna.load_study(study_name=study_name, storage=DATABASE_URI)\n",
    "best_params = [0] * params_size\n",
    "\n",
    "for i in range(params_size):\n",
    "    best_params[i] = study.best_params[f'param_{i}']\n",
    "\n",
    "best_params = np.array(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-544.0852950884679"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial: 0, total_reward: -83.98278388278466\n",
      "trial: 1, total_reward: 356.76274509799777\n",
      "trial: 2, total_reward: 660.5299212598271\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-311.1032941583467"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "play(best_params, seed_num=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m vae \u001b[39m=\u001b[39m VAE()\n\u001b[0;32m      3\u001b[0m checkpoint \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mvae.pth\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_size = 32\n",
    "a_size = 3\n",
    "h_size = 256\n",
    "\n",
    "params_size = (z_size + h_size) * a_size + a_size\n",
    "\n",
    "rewards_through_gens = []\n",
    "generation = 1\n",
    "\n",
    "def reshape_state(state):\n",
    "    HEIGHT = 64\n",
    "    WIDTH = 64\n",
    "    state = state[0:84, :, :]\n",
    "    state = np.array(Image.fromarray(state).resize((HEIGHT, WIDTH)))\n",
    "    state = state / 255.0\n",
    "    return state\n",
    "\n",
    "def decide_action(v, m, c, state, hidden, cell, device, use_world_model=False):\n",
    "    hidden = hidden.reshape(-1)\n",
    "    cell = cell.reshape(-1)\n",
    "\n",
    "    state = reshape_state(state)\n",
    "    state = np.moveaxis(state, 2, 0)\n",
    "    state = np.reshape(state, (-1, 3, 64, 64))\n",
    "    state = torch.tensor(state, dtype=torch.float32).to(device)\n",
    "    z, _, _ = v.encode(state)\n",
    "    z = z.detach().numpy()\n",
    "    z = z.reshape(-1)\n",
    "    a = c.forward_onlyz(z) # only z\n",
    "    z = torch.tensor(z, dtype=torch.float32).to(device).reshape(1, 1, -1)\n",
    "    a = torch.tensor(a, dtype=torch.float32).to(device).reshape(1, 1, -1)\n",
    "    hidden = torch.tensor(hidden, dtype=torch.float32).to(device).reshape(1, 1, -1)\n",
    "    cell = torch.tensor(cell, dtype=torch.float32).to(device).reshape(1, 1, -1)\n",
    "    pi, mu, logsigma, next_hidden, next_cell = m(z, a, hidden, cell)\n",
    "\n",
    "    pi, mu, logsigma = pi.detach().numpy().reshape(-1), mu.detach().numpy().reshape(-1), logsigma.detach().numpy().reshape(-1)\n",
    "    next_hidden, next_cell = next_hidden.detach().numpy().reshape(-1), next_cell.detach().numpy().reshape(-1)\n",
    "    a = a.detach().numpy().reshape(-1)\n",
    "    if use_world_model:\n",
    "        return a, pi, mu, logsigma, next_hidden, next_cell\n",
    "    else:\n",
    "        return a, next_hidden, next_cell\n",
    "\n",
    "def play(params, seed_num=0):\n",
    "    with torch.no_grad():\n",
    "        device = torch.device('cpu')\n",
    "        vae = VAE()\n",
    "        checkpoint = torch.load('vae.pth')\n",
    "        vae.load_state_dict(checkpoint['model_state_dict'])\n",
    "        vae = vae.eval()\n",
    "        vae.to(device)\n",
    "\n",
    "        mdnrnn = MDNRNN().to(device)\n",
    "        checkpoint = torch.load('mdnrnn.pth')\n",
    "        mdnrnn.load_state_dict(checkpoint['model_state_dict'])\n",
    "        mdnrnn = mdnrnn.eval()\n",
    "        mdnrnn.to(device)\n",
    "\n",
    "        controller = Controller(z_size, a_size, h_size, params)\n",
    "\n",
    "        env = gym.make('CarRacing-v2', render_mode='rgb_array', domain_randomize=True)\n",
    "        env.reset(seed=seed_num)\n",
    "\n",
    "        _NUM_TRIALS = 3\n",
    "        agent_reward = 0\n",
    "\n",
    "        for trial in range(_NUM_TRIALS):\n",
    "            save_frame = []\n",
    "            state, _ = env.reset()\n",
    "            np.random.seed(int(str(time.time()*1000000)[10:13]))\n",
    "            position = np.random.randint(len(env.track))\n",
    "            env.car = Car(env.world, *env.track[position][1:4])\n",
    "\n",
    "            hidden = torch.zeros(1, 1, 256).float().to(device)\n",
    "            cell = torch.zeros(1, 1, 256).float().to(device)\n",
    "\n",
    "            total_reward = 0.0\n",
    "            steps = 0\n",
    "\n",
    "            while True:\n",
    "                action, hidden, cell = decide_action(vae, mdnrnn, controller, state, hidden, cell, device)\n",
    "                state, reward, done, _, _ = env.step(action)\n",
    "                # print(action)\n",
    "                # print(done)\n",
    "                save_frame.append(state)\n",
    "                total_reward += reward\n",
    "                steps += 1\n",
    "                if steps > 3000 or done:\n",
    "                    break\n",
    "                # if done:\n",
    "                    # break\n",
    "        \n",
    "            agent_reward += total_reward\n",
    "            print('trial: {}, total_reward: {}'.format(trial, total_reward))\n",
    "            images = []\n",
    "            for i in range(len(save_frame)):\n",
    "                images.append(save_frame[i])\n",
    "            imageio.mimsave(f'traial_{trial+1}.gif', images, duration=20)\n",
    "        \n",
    "        env.close()\n",
    "\n",
    "\n",
    "        return -(agent_reward / _NUM_TRIALS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_torch_world_models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
